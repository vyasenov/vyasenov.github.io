---
title: "The Many Flavors of Propensity Score Methods for Causal Inference"
date: "2025-04-27"
categories: [causal inference, propensity scores]
---

## Background

If matching is the hammer in the causal inference toolbox, the **propensity score** is the blueprint that helps you decide where to swing it. Introduced by Rosenbaum and Rubin in 1983, the propensity score—the probability of receiving treatment given observed covariates—has become the workhorse for handling confounding in observational studies.

But here’s the thing: the propensity score itself is just the starting point. There are **many ways to use** propensity scores. You can match on them, stratify your sample, weight your observations, or plug them into doubly robust estimators that combine modeling of both the treatment and the outcome. You can tweak how you weight the units—downweighting those with extreme scores or focusing on the region where treated and control groups overlap.

In this post, we’ll explore the many flavors of propensity score methods: when to use them, how they work, and what their pros and cons are. The focus is on intuition, math, and practice—not code.

## Notation

We’re back in the familiar causal inference setup:

- $D_i \in \{0, 1\}$: treatment indicator.
- $X_i$: observed covariates.
- $Y_i(1), Y_i(0)$: potential outcomes.

The **propensity score** is:
$$
e(X_i) = \mathbb{P}(D_i = 1 \mid X_i).
$$

The key result from Rosenbaum and Rubin (1983):
$$
(Y(1), Y(0)) \perp D \mid e(X),
$$
meaning that, conditional on the propensity score, treatment assignment is as good as random.

## A Closer Look

### Nearest Neighbor Matching on Propensity Score

This is often the first method people try after estimating the propensity score. Once $e(X)$ is estimated, treated units are matched to control units with the **closest propensity scores** (nearest neighbor). You can match one-to-one, one-to-many, with or without replacement.

**When to use it?** When the number of controls is large enough to find good matches for treated units.

**Strengths:** Simple and intuitive; reduces high-dimensional matching to one dimension.

**Weaknesses:** Balance on the propensity score doesn’t guarantee balance on covariates; sensitive to poor matches.

---

### Caliper Matching

Caliper matching adds a threshold: only match treated and control units if their propensity scores are within a specified distance (the caliper). Often the caliper is set to **0.2 times the standard deviation of the logit of the propensity score**, following Rosenbaum and Rubin’s recommendation.

**When to use it?** To avoid bad matches in nearest neighbor matching.

**Strengths:** Prevents extreme mismatches; improves balance.

**Weaknesses:** May discard treated units if no control is close enough.

---

### Stratification (Subclassification) on the Propensity Score

Here, the range of propensity scores is divided into $K$ strata (often quintiles), and treatment effects are estimated **within each stratum**, then averaged across strata.

**When to use it?** When matching isn’t feasible or you prefer a more aggregate approach.

**Strengths:** Easy to implement, balances on average within strata.

**Weaknesses:** Coarse adjustment; may not fully eliminate bias within strata.

---

### Inverse Probability Weighting (IPW)

IPW turns the propensity score into weights:
$$
w_i = \frac{D_i}{e(X_i)} + \frac{1 - D_i}{1 - e(X_i)}.
$$
This reweights the sample so that treated and control groups resemble each other on observed covariates.

**When to use it?** When you want to use the whole dataset and avoid discarding units.

**Strengths:** Simple and fully utilizes all observations.

**Weaknesses:** Sensitive to extreme propensity scores near 0 or 1, which can lead to huge weights and unstable estimates.

---

### Augmented IPW (AIPW) / Doubly Robust Estimators

AIPW combines IPW with **outcome modeling** (regression adjustment). The key appeal: if either the propensity score model **or** the outcome model is correct (but not necessarily both), the estimator is consistent. This is called the **doubly robust property**.

The AIPW estimator for the ATE looks like:
$$
\hat{\tau}_{\text{AIPW}} = \frac{1}{n} \sum_{i=1}^n \left[ \frac{D_i (Y_i - \hat{m}_1(X_i))}{e(X_i)} - \frac{(1 - D_i) (Y_i - \hat{m}_0(X_i))}{1 - e(X_i)} + \hat{m}_1(X_i) - \hat{m}_0(X_i) \right],
$$
where $\hat{m}_d(X)$ is the predicted outcome for treatment group $d$.

**When to use it?** When you want robust estimation and are unsure about model correctness.

**Strengths:** Doubly robust consistency. Efficient use of data.

**Weaknesses:** Computational complexity; requires both models to be estimated.

---

### Covariate Balancing Propensity Score (CBPS)

CBPS, introduced by Imai and Ratkovic (2014), directly estimates the propensity score **while optimizing covariate balance**. Instead of fitting a logistic regression and then checking balance, CBPS ensures balance is achieved *as part of the estimation process*.

**When to use it?** When standard propensity score estimation leads to poor balance.

**Strengths:** Good balance without iterative tuning; works directly toward the matching goal.

**Weaknesses:** More complex to implement; less widely available in standard packages.

---

### Overlap Weights

Overlap weighting focuses on the **region of common support**—where treated and control units both exist—by assigning weights:
$$
w_i = D_i (1 - e(X_i)) + (1 - D_i) e(X_i).
$$
This downweights units with extreme scores near 0 or 1 and emphasizes comparability.

**When to use it?** When you want to avoid extrapolation and focus on the units where treatment and control overlap.

**Strengths:** Naturally avoids instability from extreme weights; targets the "overlap population."

**Weaknesses:** Estimates effects for the overlap population, not necessarily ATE or ATT.

---

### Entropy Balancing

Entropy balancing directly reweights the control group so that the **moments of the covariates (mean, variance, etc.) match exactly** between treated and control groups. Instead of matching or stratifying, this solves a constrained optimization problem that minimizes the Kullback-Leibler divergence of weights subject to balance constraints.

**When to use it?** When balance is hard to achieve with traditional weighting.

**Strengths:** Guarantees exact balance on chosen covariate moments. Fully utilizes the data.

**Weaknesses:** Requires specifying which moments to balance; can be sensitive to that choice.

---

## Bottom Line

- **Matching** methods (nearest neighbor, caliper) are intuitive and interpretable but can discard data.
- **Stratification** offers simplicity and full data use but may not fully balance covariates.
- **IPW** uses all data but can suffer from instability due to extreme weights.
- **AIPW** gives the best of both worlds with double robustness.
- **CBPS** directly targets balance in the propensity score estimation.
- **Overlap weights** avoid the problem of extreme scores and focus on the common support.
- **Entropy balancing** guarantees exact covariate balance via weighting without matching or stratification.

## Where to Learn More

For the original introduction to propensity scores, see Rosenbaum and Rubin’s (1983) landmark paper. Imai and Ratkovic’s (2014) work on CBPS is a must-read for understanding balance-focused estimation. The textbook *Causal Inference for Statistics, Social, and Biomedical Sciences* by Imbens and Rubin (2015) provides excellent coverage of these methods. There are also great tutorials and vignettes in R packages like `MatchIt`, `twang`, and `WeightIt`.

## References

- Rosenbaum, P. R., & Rubin, D. B. (1983). The central role of the propensity score in observational studies for causal effects. *Biometrika*, 70(1), 41–55.

- Imai, K., & Ratkovic, M. (2014). Covariate balancing propensity score. *Journal of the Royal Statistical Society: Series B (Statistical Methodology)*, 76(1), 243–263.

- Imbens, G. W., & Rubin, D. B. (2015). *Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction*. Cambridge University Press.

- Hainmueller, J. (2012). Entropy balancing for causal effects. *Political Analysis*, 20(1), 25–46.

---
---

Propensity Score Methods Applied to the Iris Dataset

The following examples apply several popular propensity score methods to the Iris dataset using both R and Python. For demonstration, we define an artificial binary treatment (`D`) based on petal length. The outcome variable is `Sepal.Length`, and the predictors are the remaining covariates.

Propensity Score Estimation (Logistic Regression)

::::{.panel-tabset}

#### R
```r
library(MatchIt)
data(iris)
iris$D <- ifelse(iris$Petal.Length > 3, 1, 0)
ps_model <- glm(D ~ Sepal.Width + Petal.Width, data = iris, family = binomial)
summary(ps_model)
```

#### Python
```python
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import load_iris
import pandas as pd
import numpy as np

iris = load_iris(as_frame=True).frame
iris['D'] = (iris['petal length (cm)'] > 3).astype(int)
X = iris[['sepal width (cm)', 'petal width (cm)']]
y = iris['D']
model = LogisticRegression().fit(X, y)
model.coef_, model.intercept_
```
::::

Nearest Neighbor Matching

::::{.panel-tabset}

#### R
```r
matchit_nn <- matchit(D ~ Sepal.Width + Petal.Width, data = iris, method = "nearest")
summary(matchit_nn)
```

#### Python
```python
from causalinference import CausalModel
cm = CausalModel(iris[['sepal width (cm)', 'petal width (cm)']].values, iris['D'].values, iris['sepal length (cm)'].values)
cm.est_via_matching()
cm.estimates
```
::::

Caliper Matching

::::{.panel-tabset}

#### R
```r
matchit_caliper <- matchit(D ~ Sepal.Width + Petal.Width, data = iris, method = "nearest", caliper = 0.2)
summary(matchit_caliper)
```

#### Python
```python
# caliper matching in Python is not built-in; would require manual implementation or use DoWhy or related packages
```
::::


Stratification (Subclassification)

::::{.panel-tabset}

#### R
```r
matchit_strat <- matchit(D ~ Sepal.Width + Petal.Width, data = iris, method = "subclass", subclass = 5)
summary(matchit_strat)
```

#### Python
```python
# Stratification would require binning the propensity score and estimating within strata manually
```
::::

::::{.panel-tabset}

Inverse Probability Weighting (IPW)

#### R
```r
iris$ps <- predict(ps_model, type = "response")
iris$weights <- ifelse(iris$D == 1, 1 / iris$ps, 1 / (1 - iris$ps))
summary(iris$weights)
```

#### Python
```python
iris['ps'] = model.predict_proba(X)[:,1]
iris['weights'] = np.where(iris['D'] == 1, 1 / iris['ps'], 1 / (1 - iris['ps']))
iris['weights'].describe()
```
::::

Augmented IPW (AIPW) / Doubly Robust

::::{.panel-tabset}

#### R
```r
# Requires additional outcome modeling and manual implementation
# Use packages like AIPW or drtmle for robust estimators
```

#### Python
```python
# Requires DoWhy, EconML, or custom implementation for AIPW
```
::::

Covariate Balancing Propensity Score (CBPS)

::::{.panel-tabset}

#### R
```r
library(CBPS)
cbps_fit <- CBPS(D ~ Sepal.Width + Petal.Width, data = iris)
summary(cbps_fit)
```

#### Python
```python
# CBPS not readily available in sklearn; typically done via R or custom implementation
```
::::

Overlap Weights

::::{.panel-tabset}

#### R
```r
iris$overlap_weights <- ifelse(iris$D == 1, 1 - iris$ps, iris$ps)
summary(iris$overlap_weights)
```

#### Python
```python
iris['overlap_weights'] = np.where(iris['D'] == 1, 1 - iris['ps'], iris['ps'])
iris['overlap_weights'].describe()
```
::::

Entropy Balancing

::::{.panel-tabset}

#### R
```r
library(ebal)
control_idx <- which(iris$D == 0)
treated_idx <- which(iris$D == 1)
X_control <- iris[control_idx, c("Sepal.Width", "Petal.Width")]
eg <- ebalance(Treatment = rep(0, length(control_idx)), X = as.matrix(X_control), target.margins = colMeans(iris[treated_idx, c("Sepal.Width", "Petal.Width")]))
summary(eg)
```

#### Python
```python
# Entropy balancing in Python requires specialized packages or manual convex optimization
```
::::

