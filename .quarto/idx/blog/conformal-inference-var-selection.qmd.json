{"title":"Using Conformal Inference for Variable Importance in Machine Learning","markdown":{"yaml":{"title":"Using Conformal Inference for Variable Importance in Machine Learning","date":"2023-12-20","categories":["machine learning"]},"headingText":"Background","containsRefs":false,"markdown":"\n\n\nMany machine learning (ML) methods operate as opaque systems, generating predictions when given a dataset as input. Identifying which variables have the greatest impact on these predictions is often crucial. This adds a touch of interpretability and transparency and aids stakeholders in better understanding the relevant context. Examples abound. For instance, identifying the house attributes most important for predicting home prices, the school or hospital characteristics most strongly associated with better students’ and patients’ outcomes, etc. \n\n[Conformal inference](https://www.tandfonline.com/doi/abs/10.1080/01621459.2017.1307116) offers a novel way of measuring variable importance in ML. In an earlier article I introduced conformal inference as a tool for generating confidence intervals when making predictions for new observations, and here I will describe how we can adapt it to the context of feature importance. The approach is thus similar in spirit to the Gini Importance-based methods mentioned above.\n\n## Notation\n\nLet’s begin by setting up some notation. We have a size $n$  i.i.d. random sample of a feature vector $X$ and an outcome $Y$. The focus of conformal inference is on constructing a “confidence interval” for predicting a new observation $Y_{n+1}$ given a new feature realization $X_{n+1}$. I denote the estimate of the mean function by $\\hat{\\mu}$ and the same estimate when removing feature $j$ from $X $ by $\\hat{\\mu}_{-j}$.\n\nPlease refer to my previous article for more details on the conformal inference framework, methodology and its properties.\n\n## A Closer Look\n\n### Refresher on Variable Importance\n\nThe idea of measuring which variables contribute most to a prediction model is not new. The data scientist’s toolbox contains some useful techniques designed to measure variable importance in ML models. Popular choices include:\n\n- **Gini Importance and Information Gain** in tree-based models (e.g., random forest, gradient boosting) measure the decrease in various within-leaf impurity indexes caused by excluding a certain variable.  The larger the loss, the more important the variable.\n- **SHAP Values** use a cooperative game-theoretic approach to measure each variable’s contribution to the final model’s prediction.\n- **Permutation Importance** assesses a variable’s significance by randomly shuffling its values and comparing the change in the model’s performance. The larger the drop, the more important the variable.\n- **Variable Coefficients** in linear ML models (e.g., Lasso, Ridge) can directly signal importance. This requires an appropriate standardization before fitting the model (to make sure all features are on a level playing field).\n\n### Variable Importance with Conformal Inference\n\nWe can measure the prediction error associated with dropping a feature $j$ when predicting a new observation $Y_{n+1}$ by:\n\n  $$\\Delta_j^{n+1} = |Y_{n+1} - \\hat{\\mu}_{-j}(X_{n+1})| - |Y_{n+1}-\\hat{\\mu}(X_{n+1})|.$$\n\nThe main idea is to use conformal inference ideas to construct a confidence interval for this prediction loss, $\\Delta_j^{n+1}$, as a signal whether that variable is relevant in predicting the outcome.\n\nSpecifically, let $CI(\\cdot)$ denote the conformal inference interval for $Y_{n+1}$ given $X_{n+1}$. Then, the interval\n\n  $$S_j(x)=\\{ |y-\\hat{\\mu}_{-j}(x)|-|y-\\hat{\\mu}(x)| : y \\in CI(x) \\}.$$\n\nhas a valid finite-sample coverage in the sense that:\n\n  $$ P(\\Delta_j^{n+1} \\in S_j(X_{n+1})) \\geq 1-\\alpha, $$\n\nwhere $\\alpha$ is a pre-specified significance level. This holds for all $j$.\n\nWe can plot the confidence intervals $S_j(X_i)$ for $i=1 \\dots n$ and roughly interpret them as measuring variable importance. The closer the intervals are to zero, the less important the variable is for predicting new outcomes. The opposite is true as well. The further and more often it is away from zero, the more important the variable.\n\nAnother, more global, approach to using conformal inference for variable importance focuses on the distribution of $\\Delta_j(X_{n+1}, Y_{n+1})$ and conducts hypothesis testing on its median or mean. Intuitively, failing to reject a hypothesis that these statistics are non-zero is evidence that variable $j$ does not play a significant role in predicting $Y$.\n\n## Bottom Line\n\n- While many ML methods act as black boxes, attention often falls on measuring individual variable importance.\n\n- Conformal inference offers a new way for data scientists to quantify the influence of each variable to the model performance.\n\n- The main idea is to use conformal inference to construct a confidence interval for the loss in prediction accuracy associated with removing a feature from the dataset.\n\n## Where to Learn More\n\nSee Section 6 in [Lei et al. (2018)](https://www.tandfonline.com/doi/abs/10.1080/01621459.2017.1307116) and the references therein.\n\n## References\n\nLei, J., G’Sell, M., Rinaldo, A., Tibshirani, R. J., & Wasserman, L. (2018). Distribution-free predictive inference for regression. Journal of the American Statistical Association, 113(523), 1094-1111.\n\nLei, J., Rinaldo, A., & Wasserman, L. (2015). A conformal prediction approach to explore functional data. Annals of Mathematics and Artificial Intelligence, 74, 29-43.\n\nShafer, G., & Vovk, V. (2008). A Tutorial on Conformal Prediction. Journal of Machine Learning Research, 9(3).\n\nVovk, V., Gammerman, A., & Shafer, G. (2005). Algorithmic learning in a random world (Vol. 29). New York: Springer.","srcMarkdownNoYaml":"\n\n## Background\n\nMany machine learning (ML) methods operate as opaque systems, generating predictions when given a dataset as input. Identifying which variables have the greatest impact on these predictions is often crucial. This adds a touch of interpretability and transparency and aids stakeholders in better understanding the relevant context. Examples abound. For instance, identifying the house attributes most important for predicting home prices, the school or hospital characteristics most strongly associated with better students’ and patients’ outcomes, etc. \n\n[Conformal inference](https://www.tandfonline.com/doi/abs/10.1080/01621459.2017.1307116) offers a novel way of measuring variable importance in ML. In an earlier article I introduced conformal inference as a tool for generating confidence intervals when making predictions for new observations, and here I will describe how we can adapt it to the context of feature importance. The approach is thus similar in spirit to the Gini Importance-based methods mentioned above.\n\n## Notation\n\nLet’s begin by setting up some notation. We have a size $n$  i.i.d. random sample of a feature vector $X$ and an outcome $Y$. The focus of conformal inference is on constructing a “confidence interval” for predicting a new observation $Y_{n+1}$ given a new feature realization $X_{n+1}$. I denote the estimate of the mean function by $\\hat{\\mu}$ and the same estimate when removing feature $j$ from $X $ by $\\hat{\\mu}_{-j}$.\n\nPlease refer to my previous article for more details on the conformal inference framework, methodology and its properties.\n\n## A Closer Look\n\n### Refresher on Variable Importance\n\nThe idea of measuring which variables contribute most to a prediction model is not new. The data scientist’s toolbox contains some useful techniques designed to measure variable importance in ML models. Popular choices include:\n\n- **Gini Importance and Information Gain** in tree-based models (e.g., random forest, gradient boosting) measure the decrease in various within-leaf impurity indexes caused by excluding a certain variable.  The larger the loss, the more important the variable.\n- **SHAP Values** use a cooperative game-theoretic approach to measure each variable’s contribution to the final model’s prediction.\n- **Permutation Importance** assesses a variable’s significance by randomly shuffling its values and comparing the change in the model’s performance. The larger the drop, the more important the variable.\n- **Variable Coefficients** in linear ML models (e.g., Lasso, Ridge) can directly signal importance. This requires an appropriate standardization before fitting the model (to make sure all features are on a level playing field).\n\n### Variable Importance with Conformal Inference\n\nWe can measure the prediction error associated with dropping a feature $j$ when predicting a new observation $Y_{n+1}$ by:\n\n  $$\\Delta_j^{n+1} = |Y_{n+1} - \\hat{\\mu}_{-j}(X_{n+1})| - |Y_{n+1}-\\hat{\\mu}(X_{n+1})|.$$\n\nThe main idea is to use conformal inference ideas to construct a confidence interval for this prediction loss, $\\Delta_j^{n+1}$, as a signal whether that variable is relevant in predicting the outcome.\n\nSpecifically, let $CI(\\cdot)$ denote the conformal inference interval for $Y_{n+1}$ given $X_{n+1}$. Then, the interval\n\n  $$S_j(x)=\\{ |y-\\hat{\\mu}_{-j}(x)|-|y-\\hat{\\mu}(x)| : y \\in CI(x) \\}.$$\n\nhas a valid finite-sample coverage in the sense that:\n\n  $$ P(\\Delta_j^{n+1} \\in S_j(X_{n+1})) \\geq 1-\\alpha, $$\n\nwhere $\\alpha$ is a pre-specified significance level. This holds for all $j$.\n\nWe can plot the confidence intervals $S_j(X_i)$ for $i=1 \\dots n$ and roughly interpret them as measuring variable importance. The closer the intervals are to zero, the less important the variable is for predicting new outcomes. The opposite is true as well. The further and more often it is away from zero, the more important the variable.\n\nAnother, more global, approach to using conformal inference for variable importance focuses on the distribution of $\\Delta_j(X_{n+1}, Y_{n+1})$ and conducts hypothesis testing on its median or mean. Intuitively, failing to reject a hypothesis that these statistics are non-zero is evidence that variable $j$ does not play a significant role in predicting $Y$.\n\n## Bottom Line\n\n- While many ML methods act as black boxes, attention often falls on measuring individual variable importance.\n\n- Conformal inference offers a new way for data scientists to quantify the influence of each variable to the model performance.\n\n- The main idea is to use conformal inference to construct a confidence interval for the loss in prediction accuracy associated with removing a feature from the dataset.\n\n## Where to Learn More\n\nSee Section 6 in [Lei et al. (2018)](https://www.tandfonline.com/doi/abs/10.1080/01621459.2017.1307116) and the references therein.\n\n## References\n\nLei, J., G’Sell, M., Rinaldo, A., Tibshirani, R. J., & Wasserman, L. (2018). Distribution-free predictive inference for regression. Journal of the American Statistical Association, 113(523), 1094-1111.\n\nLei, J., Rinaldo, A., & Wasserman, L. (2015). A conformal prediction approach to explore functional data. Annals of Mathematics and Artificial Intelligence, 74, 29-43.\n\nShafer, G., & Vovk, V. (2008). A Tutorial on Conformal Prediction. Journal of Machine Learning Research, 9(3).\n\nVovk, V., Gammerman, A., & Shafer, G. (2005). Algorithmic learning in a random world (Vol. 29). New York: Springer."},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../code/styles.css"],"toc":true,"filters":["code-insertion"],"output-file":"conformal-inference-var-selection.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.24","resources":["../code/open-links-new-tab.js","../code/back-to-top.js"],"theme":{"light":"cosmo","dark":"cyborg"},"header-includes":["<script type='text/javascript' src='https://platform-api.sharethis.com/js/sharethis.js#property=680ee8d89f7a510019a96bcf&product=inline-share-buttons' async='async'></script>\n<script src=\"../code/open-links-new-tab.js\"></script>  \n<script src=\"../code/back-to-top.js\"></script>\n<link href=\"https://fonts.googleapis.com/css2?family=Fira+Code&family=Source+Code+Pro&display=swap\" rel=\"stylesheet\">\n"],"page-layout":"full","includes":{"after-body":["../_includes/comments.html",{"text":"<button id=\"back-to-top\" onclick=\"scrollToTop()\">↑</button>\n"}]},"insert-before-post":"_sharebuttons.md","title":"Using Conformal Inference for Variable Importance in Machine Learning","date":"2023-12-20","categories":["machine learning"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}