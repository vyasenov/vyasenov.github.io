{"title":"Causation without Correlation","markdown":{"yaml":{"title":"Causation without Correlation","date":"2024-11-21","categories":["causal inference","correlation"]},"headingText":"Background","containsRefs":false,"markdown":"\n\n\nWhile most people understand that correlation doesn’t imply causation, it might surprise many to learn that causation doesn’t always result in correlation. In the absence of randomization, causal relationships do not require observable correlation. This counterintuitive concept challenges our natural tendency to expect that when one variable causes change in another, we should see a clear (linear) relationship between them. The core idea is that confounding variables or other statistical phenomena can obscure the causal link. Let’s explore this concept through a few examples.\n\n## A Closer Look\n\nIn the popular book [Causal Inference: The Mixtape](https://mixtape.scunning.com/), Scott Cunningham gives an example of a sailor steering a boat in stormy waters. The wind may be so strong as to offset the boat’s natural moving direction. For instance, the sailor might steer (treatment, $T$) the boat north, while a southward wind (confounder, $Z$) causes the boat to move east (outcome, $Y$). An onlooker would not observe any direct relationship between $T$ and $Y$, even though $T$ causes $Y$.\n\nAt first, this sounds counterintuitive. On second thought, such patterns are everywhere. Consider the following.\n\n### Example 1: Parenting Styles and Children’s Behavior\n\nA parent might adopt a stricter parenting style ($T$) in response to a child’s behavioral issues ($Y$). However, other influences, like peer pressure or school environment ($Z$), may also shape the child’s behavior, sometimes overriding the parent’s efforts. The net observable outcome could show no correlation between stricter parenting and improved behavior, even though the stricter parenting is causally effective in certain contexts.\n\nThis idea can be taken one step further. An observable relationship might even appear positive when the causal relationship is negative.\n\n### Example 2: Ice Cream Sales and Shark Attacks\n\nImagine two beaches with vastly different safety protocols ($Z$): one has lifeguards trained to prevent shark attacks, while the other does not. On the safer beach, higher ice cream sales ($T$) correlate positively with shark attacks ($Y$), because more people visit the beach when safety protocols are in place. This hides the fact that proper safety protocols causally reduce shark attacks. The observed positive correlation between $T$ and $Y$ masks the negative causal relationship.\n\n### Example 3: Nonlinearity\n\nA more trivial scenario leading to the lack of correlation in causal relationships is non-linearity. I do not find this scenario too insightful simply because it can be avoided by using more sophisticated measures of correlation. See my earlier post on the Chatterjee correlation coefficient.\n\nExamples of such relationships abound. Consider a parabolic relationship, where increasing a drug’s dosage initially improves patient outcomes but becomes harmful at higher doses. Despite a clear causal relationship, the (Pearson) correlation coefficient might be close to zero because the relationship is not linear.\n\n### Example 4: Threshold Effects and Phase Transitions\n\nTake the classic example of temperature and water’s state. Increasing temperature causes water to change state at exactly 100°C. Below and above this point, temperature changes cause minimal effects on the water’s state. Aggregating these observations leads to a weak correlation, despite the temperature being the direct cause of the phase transition.\n\nOther fascinating scenarios include Lord’s Paradox, and Simpson’s Paradox, where a causal relationship can appear to reverse or disappear when data is aggregated.\n\n### Example 5: Hospital Mortality Rates\n\nSuppose two hospitals treat patients with different levels of severity. Hospital $A$ specializes in high-risk patients, while Hospital $B$ treats mostly low-risk cases. When comparing raw mortality rates ($Y$), Hospital $A$ might appear worse, even though it provides superior care ($T$). Disaggregating the data by risk level reveals the causal effect of Hospital $A$’s superior treatment within each group.\n\n## Bottom Line\n\n- In observational data causation does not require correlation.\n\n- Correlation—or the lack thereof—can obscure our understanding of causal relationships.\n\n- With the right tools and frameworks, we can disentangle the true causal effects, even when correlation gives us a wrong answer.\n\n## References\n\nCunningham, S. (2021). Causal inference: The mixtape. Yale university press.","srcMarkdownNoYaml":"\n\n## Background\n\nWhile most people understand that correlation doesn’t imply causation, it might surprise many to learn that causation doesn’t always result in correlation. In the absence of randomization, causal relationships do not require observable correlation. This counterintuitive concept challenges our natural tendency to expect that when one variable causes change in another, we should see a clear (linear) relationship between them. The core idea is that confounding variables or other statistical phenomena can obscure the causal link. Let’s explore this concept through a few examples.\n\n## A Closer Look\n\nIn the popular book [Causal Inference: The Mixtape](https://mixtape.scunning.com/), Scott Cunningham gives an example of a sailor steering a boat in stormy waters. The wind may be so strong as to offset the boat’s natural moving direction. For instance, the sailor might steer (treatment, $T$) the boat north, while a southward wind (confounder, $Z$) causes the boat to move east (outcome, $Y$). An onlooker would not observe any direct relationship between $T$ and $Y$, even though $T$ causes $Y$.\n\nAt first, this sounds counterintuitive. On second thought, such patterns are everywhere. Consider the following.\n\n### Example 1: Parenting Styles and Children’s Behavior\n\nA parent might adopt a stricter parenting style ($T$) in response to a child’s behavioral issues ($Y$). However, other influences, like peer pressure or school environment ($Z$), may also shape the child’s behavior, sometimes overriding the parent’s efforts. The net observable outcome could show no correlation between stricter parenting and improved behavior, even though the stricter parenting is causally effective in certain contexts.\n\nThis idea can be taken one step further. An observable relationship might even appear positive when the causal relationship is negative.\n\n### Example 2: Ice Cream Sales and Shark Attacks\n\nImagine two beaches with vastly different safety protocols ($Z$): one has lifeguards trained to prevent shark attacks, while the other does not. On the safer beach, higher ice cream sales ($T$) correlate positively with shark attacks ($Y$), because more people visit the beach when safety protocols are in place. This hides the fact that proper safety protocols causally reduce shark attacks. The observed positive correlation between $T$ and $Y$ masks the negative causal relationship.\n\n### Example 3: Nonlinearity\n\nA more trivial scenario leading to the lack of correlation in causal relationships is non-linearity. I do not find this scenario too insightful simply because it can be avoided by using more sophisticated measures of correlation. See my earlier post on the Chatterjee correlation coefficient.\n\nExamples of such relationships abound. Consider a parabolic relationship, where increasing a drug’s dosage initially improves patient outcomes but becomes harmful at higher doses. Despite a clear causal relationship, the (Pearson) correlation coefficient might be close to zero because the relationship is not linear.\n\n### Example 4: Threshold Effects and Phase Transitions\n\nTake the classic example of temperature and water’s state. Increasing temperature causes water to change state at exactly 100°C. Below and above this point, temperature changes cause minimal effects on the water’s state. Aggregating these observations leads to a weak correlation, despite the temperature being the direct cause of the phase transition.\n\nOther fascinating scenarios include Lord’s Paradox, and Simpson’s Paradox, where a causal relationship can appear to reverse or disappear when data is aggregated.\n\n### Example 5: Hospital Mortality Rates\n\nSuppose two hospitals treat patients with different levels of severity. Hospital $A$ specializes in high-risk patients, while Hospital $B$ treats mostly low-risk cases. When comparing raw mortality rates ($Y$), Hospital $A$ might appear worse, even though it provides superior care ($T$). Disaggregating the data by risk level reveals the causal effect of Hospital $A$’s superior treatment within each group.\n\n## Bottom Line\n\n- In observational data causation does not require correlation.\n\n- Correlation—or the lack thereof—can obscure our understanding of causal relationships.\n\n- With the right tools and frameworks, we can disentangle the true causal effects, even when correlation gives us a wrong answer.\n\n## References\n\nCunningham, S. (2021). Causal inference: The mixtape. Yale university press."},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../code/styles.css"],"toc":true,"include-in-header":[{"text":"<script src=\"../code/open-links-new-tab.js\"></script>\n"}],"filters":["code-insertion"],"output-file":"causation-without-correlation.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.24","resources":["../code/open-links-new-tab.js"],"theme":{"light":"cosmo","dark":"cyborg"},"header-includes":["<script type='text/javascript' src='https://platform-api.sharethis.com/js/sharethis.js#property=680ee8d89f7a510019a96bcf&product=inline-share-buttons' async='async'></script>"],"page-layout":"full","includes":{"after-body":["../_includes/comments.html"]},"insert-before-post":"_sharebuttons.md","title":"Causation without Correlation","date":"2024-11-21","categories":["causal inference","correlation"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}