{"title":"Binscatter: A New Visual Tool for Data Analysis","markdown":{"yaml":{"title":"Binscatter: A New Visual Tool for Data Analysis","date":"2025-02-09","categories":["correlation"]},"headingText":"Background","containsRefs":false,"markdown":"\n\n\nIn the realm of data visualization, the classical scatter plot has long been a staple for exploring bivariate relationships. However, as datasets grow larger and more complex, traditional scatter plots can become cluttered and less informative. Privacy concerns may also limit the ability to plot raw data, and simple bivariate plots often fail to reveal causal relationships. This is where binscatter, or binned scatter plots, come into play.\n\nBinscatter offers a cleaner, more interpretable way to visualize the relationship between two variables, especially when dealing with large datasets. By aggregating data points into bins and plotting the average outcome within each bin, binscatter simplifies the visualization, making it easier to discern patterns and trends. It’s particularly useful for:\n\n- Intuitive visualization for large datasets by grouping data into bins.\n- Highlighting trends and relationship between variables effectively.\n- Extending these ideas to control for covariates.\n\nIn this article, I will introduce binscatter, explore its mathematical foundation, and demonstrate its utility with an example in `R` and `python`.\n\n## Notation\n\nTo formalize binscatter, let’s define the following:\n\n- $X$: The independent/predictor variable.\n- $Y$: The dependent/outcome/response variable.\n- $n$: The number of observations in the dataset.\n- $K$: The number of bins into which $X$ is divided.\n- $\\bar{Y}_k$: The mean of $Y$ for observations falling in the $k$-th bin of $X$. Similarly for $\\bar{X}_k$.\n- $B_k$​: The observations falling in the $k$-th bin.\n- $W$: The covariate to be controlled. This can be a vector too.\n\n## A Closer Look\n\n### Formal Definition\n\nA binscatter plot is constructed by partitioning the range of the independent variable $X$ into a fixed number of $K$ bins, $B_1,\\dots,B_K$ typically using empirical quantiles. This ensures each bin is of roughly the same size. Within each bin, the average value of the dependent variable $Y$ is calculated. These averages are then plotted against the midpoint of each bin, $\\bar{X}$, resulting in a series of points that represent an estimate of conditional mean of $Y$ given $X$, $E[Y\\mid X]$.\n\nIn technical jargon binscatter provides a nonparametric estimate of the conditional mean function, offering a visual summary of the relationship between the two variables. The resulting graph allows assessment of linearity, monotonicity, convexity, etc.\n\n### The Algorithm\n\nHere is the step-by-step recipe for constructing a binscatter plot.\n\n::: {.callout-note title=\"Algorithm:\"}\n\n1. **Bin construction**: Divide the range of $X$ into $K$ equal-width bins, or use quantile-based bins for equal sample sizes within bins. For example, with $K=10$, the observations in $B_1$ would be those between the minimum value of $X$ and that of its tenth percentile.\n\n2. **Mean calculation**: Compute the mean of $Y$ within each bin:\n\n  $$\\bar{Y}_k= \\frac{1}{|B_k|} \\sum_{i \\in B_k} Y_i,$$\n\nwhere $|B_k|$ is the number of observations in bin $B_k$​.\n\n3. **Plotting**: Plot $\\bar{Y}_k$ against the midpoints of each bin, $\\bar{X}_k$.\n:::\n\n*Software Package*: [binsreg](https://nppackages.github.io/binsreg/).\n\nQuite simple, right? Let’s explore certain useful extensions of this idea.\n\n### Adjusting for Covariates: The Wrong Way\n\nIn many applications, it is essential to control for additional covariates $W$ to isolate the relationship between the primary variables of interest. The object of interest then becomes the conditional mean $E[Y\\mid W,X]$. An example would be focusing on the relationship between income ($Y$) and education level ($X$) when controlling for parental education ($W$).\n\nA common but flawed approach to incorporating covariates in binscatter is residualized binscatter. This method involves first regressing separately both $Y$ and $X$ on the covariates $W$ to obtain residuals $\\hat{u}_Y$​ and $\\hat{u}_X$​, and then applying the binscatter method to these residuals:\n\n$$\\bar{\\hat{u}}_{Y,k} = \\frac{1}{|B_k|} \\sum_{i \\in B_k} \\hat{u}_{X,i}.$$\n\nWhile this approach is motivated by the [Frisch-Waugh-Lovell](https://en.wikipedia.org/wiki/Frisch%E2%80%93Waugh%E2%80%93Lovell_theorem) theorem in linear regression, it can lead to incorrect conclusions in more general settings. The residualized binscatter may not accurately reflect the true conditional mean function, especially if the underlying relationship is nonlinear. Therefore, it is generally not recommended for empirical work.\n\n### Adjusting for Covariates: The Right Way\n\nInstead, this should be done using a semi-parametric partially linear regression model. This is achieved by modeling the conditional mean function as\n\n$$Y = \\mu_0(X) + W \\gamma_0 + \\varepsilon,$$\n\nwhere $\\mu_0(X)$ captures the main effect of $X$, and $W' \\gamma_0$ adjusts for the influence of additional covariates. Rather than residualizing, we estimate $\\mu_0(X)$ using the least-squares approach:\n\n$$(\\hat{\\beta}, \\hat{\\gamma}) = \\arg\\min_{\\beta, \\gamma} \\sum (Y- b(X)' \\beta - W' \\gamma)^2,$$\n\nwhere $b(X)$ represents the binning basis functions. The final binscatter plot displays the estimated conditional mean function\n\n  $$\\hat{\\mu}(X_k) = b(X_k)' \\hat{\\beta}$$\n\nagainst $\\bar{X}_k$, ensuring a correct visualization of the relationship between $X$ and $Y$ after accounting for the covariates $W$.\n\n### Practical Considerations\n\nA key decision is the choice of the number of bins $K$. Too few bins can oversmooth the data, masking important features, while too many bins can lead to undersmoothing, resulting in a noisy and less interpretable plot. An optimal choice of $K$ balances bias and variance, often determined using data-driven methods. To address this, [Cattaneo et al. (2024)](https://www.aeaweb.org/articles?id=10.1257/aer.20221576) propose an adaptive, Integrated Mean Squared Error (IMSE)-optimal choice of $K$ for which get a plug-in formula.\n\nThoughtful data scientist always have variance in their mind. If, for instance, we see some linear relationship between $Y$ and $X$, how can we determine whether it is statistically significant? Quantifying the uncertainty around binscatter estimates is crucial. The authors also discuss constructing confidence bands, which can be added to the plot to visually represent estimation uncertainty, enhancing both interpretability and reliability.\n\n## An Example\n\nAs an example let’s examine the relationship between the variables `Sepal.Length` and `Petal.Length` in the popular iris dataset. We will use a fixed number of ten bins. Alternatively, the package `binsreg` will automatically calculate the optimal $K$.\n\n::: {.panel-tabset}\n\n## R\n\n```r\n# clear the workspace and load libraries\nrm(list=ls())\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(binsreg)\ndata(iris)\n\n# define the number of bins\nbins <- 10\n\n# create binned data\niris_binned <- iris %>%\n  mutate(bin = cut(Sepal.Length, breaks = bins, include.lowest = TRUE)) %>%\n  group_by(bin) %>%\n  summarize(\n    bin_mid = mean(as.numeric(as.character(bin))),\n    mean_petal_length = mean(Petal.Length)\n  )\n\n# Add a panel label for the raw scatter plot\niris_raw <- iris %>% \n    mutate(panel = \"1. Raw Scatter Plot\")\n\n# Add a panel label for the binned scatter plot\niris_binned <- iris_binned %>%\n  mutate(panel = \"2. Binned Scatter Plot\")\n\n# Combine raw and binned data into a single dataset for plotting\nplot_data <- bind_rows(\niris_raw %>% rename(x = Sepal.Length, y = Petal.Length),\n  iris_binned %>% rename(x = bin_mid, y = mean_petal_length)\n)\n\n# Create the plot\nggplot(plot_data, aes(x = x, y = y)) +\n  geom_point() +\n  facet_wrap(~ panel, scales = \"free_x\", ncol = 2) +\n  labs(title = \"Comparison of Raw and Binned Scatter Plots\",\n  x = \"Sepal Length\",\n  y = \"Petal Length\") +\n  theme_minimal()\n```\n\n## Python\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load the iris dataset\nfrom sklearn.datasets import load_iris\niris_data = load_iris(as_frame=True)\niris = iris_data['data']\niris.columns = ['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']\n\n# Number of bins\nbins = 10\n\n# Create binned data\niris['bin'] = pd.cut(iris['Sepal.Length'], bins=bins, include_lowest=True)\niris_binned = iris.groupby('bin').agg(\n    bin_mid=('Sepal.Length', lambda x: (x.min() + x.max()) / 2),\n    mean_petal_length=('Petal.Length', 'mean')\n).reset_index()\n\n# Add panel labels\niris_raw = iris[['Sepal.Length', 'Petal.Length']].copy()\niris_raw['panel'] = \"1. Raw Scatter Plot\"\n\niris_binned = iris_binned.rename(columns={'bin_mid': 'Sepal.Length', 'mean_petal_length': 'Petal.Length'})\niris_binned['panel'] = \"2. Binned Scatter Plot\"\n\n# Combine raw and binned data\nplot_data = pd.concat([iris_raw, iris_binned], ignore_index=True)\n\n# Plot\nsns.set_theme(style=\"whitegrid\")\nfig, axes = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n\n# Raw scatter plot\nsns.scatterplot(\n    data=plot_data[plot_data['panel'] == \"1. Raw Scatter Plot\"],\n    x='Sepal.Length', y='Petal.Length', ax=axes[0]\n)\naxes[0].set_title(\"1. Raw Scatter Plot\")\naxes[0].set_xlabel(\"Sepal Length\")\naxes[0].set_ylabel(\"Petal Length\")\n\n# Binned scatter plot\nsns.scatterplot(\n    data=plot_data[plot_data['panel'] == \"2. Binned Scatter Plot\"],\n    x='Sepal.Length', y='Petal.Length', ax=axes[1]\n)\naxes[1].set_title(\"2. Binned Scatter Plot\")\naxes[1].set_xlabel(\"Sepal Length\")\n\n# Adjust layout\nplt.suptitle(\"Comparison of Raw and Binned Scatter Plots\")\nplt.tight_layout()\nplt.show()\n```\n\n:::\n\nHere is the resulting image. The left scatter plot displays the raw data and the right one shows the binscatter. Binscatter removes some of the clutter and highlights the linear relationship more directly.\n\n![](../images/binscatter.png)\n\n## Bottom Line\n\n- Binscatter simplifies scatterplots by aggregating data into bins and plotting means.\n\n- It is a powerful tool for visualizing relationships in large or noisy datasets.\n\n- Conditional and residualized binscatter extend its utility to controlling for covariates.\n\n- While intuitive, binscatter is sensitive to binning choices and may obscure nuances.\n\n## Where to Learn More\n\nBoth papers cited below are relatively accessible and will answer your questions. Start with Starr and Goldfarb (2020).\n\n## References\n\nCattaneo, M. D., Crump, R. K., Farrell, M. H., & Feng, Y. (2024). On Binscatter Regressions. American Economic Review, 111(3), 718–748.\n\nStarr, E., & Goldfarb, B. (2020). Binned scatterplots: A simple tool to make research easier and better. Strategic Management Journal, 41(12), 2261-2274.","srcMarkdownNoYaml":"\n\n## Background\n\nIn the realm of data visualization, the classical scatter plot has long been a staple for exploring bivariate relationships. However, as datasets grow larger and more complex, traditional scatter plots can become cluttered and less informative. Privacy concerns may also limit the ability to plot raw data, and simple bivariate plots often fail to reveal causal relationships. This is where binscatter, or binned scatter plots, come into play.\n\nBinscatter offers a cleaner, more interpretable way to visualize the relationship between two variables, especially when dealing with large datasets. By aggregating data points into bins and plotting the average outcome within each bin, binscatter simplifies the visualization, making it easier to discern patterns and trends. It’s particularly useful for:\n\n- Intuitive visualization for large datasets by grouping data into bins.\n- Highlighting trends and relationship between variables effectively.\n- Extending these ideas to control for covariates.\n\nIn this article, I will introduce binscatter, explore its mathematical foundation, and demonstrate its utility with an example in `R` and `python`.\n\n## Notation\n\nTo formalize binscatter, let’s define the following:\n\n- $X$: The independent/predictor variable.\n- $Y$: The dependent/outcome/response variable.\n- $n$: The number of observations in the dataset.\n- $K$: The number of bins into which $X$ is divided.\n- $\\bar{Y}_k$: The mean of $Y$ for observations falling in the $k$-th bin of $X$. Similarly for $\\bar{X}_k$.\n- $B_k$​: The observations falling in the $k$-th bin.\n- $W$: The covariate to be controlled. This can be a vector too.\n\n## A Closer Look\n\n### Formal Definition\n\nA binscatter plot is constructed by partitioning the range of the independent variable $X$ into a fixed number of $K$ bins, $B_1,\\dots,B_K$ typically using empirical quantiles. This ensures each bin is of roughly the same size. Within each bin, the average value of the dependent variable $Y$ is calculated. These averages are then plotted against the midpoint of each bin, $\\bar{X}$, resulting in a series of points that represent an estimate of conditional mean of $Y$ given $X$, $E[Y\\mid X]$.\n\nIn technical jargon binscatter provides a nonparametric estimate of the conditional mean function, offering a visual summary of the relationship between the two variables. The resulting graph allows assessment of linearity, monotonicity, convexity, etc.\n\n### The Algorithm\n\nHere is the step-by-step recipe for constructing a binscatter plot.\n\n::: {.callout-note title=\"Algorithm:\"}\n\n1. **Bin construction**: Divide the range of $X$ into $K$ equal-width bins, or use quantile-based bins for equal sample sizes within bins. For example, with $K=10$, the observations in $B_1$ would be those between the minimum value of $X$ and that of its tenth percentile.\n\n2. **Mean calculation**: Compute the mean of $Y$ within each bin:\n\n  $$\\bar{Y}_k= \\frac{1}{|B_k|} \\sum_{i \\in B_k} Y_i,$$\n\nwhere $|B_k|$ is the number of observations in bin $B_k$​.\n\n3. **Plotting**: Plot $\\bar{Y}_k$ against the midpoints of each bin, $\\bar{X}_k$.\n:::\n\n*Software Package*: [binsreg](https://nppackages.github.io/binsreg/).\n\nQuite simple, right? Let’s explore certain useful extensions of this idea.\n\n### Adjusting for Covariates: The Wrong Way\n\nIn many applications, it is essential to control for additional covariates $W$ to isolate the relationship between the primary variables of interest. The object of interest then becomes the conditional mean $E[Y\\mid W,X]$. An example would be focusing on the relationship between income ($Y$) and education level ($X$) when controlling for parental education ($W$).\n\nA common but flawed approach to incorporating covariates in binscatter is residualized binscatter. This method involves first regressing separately both $Y$ and $X$ on the covariates $W$ to obtain residuals $\\hat{u}_Y$​ and $\\hat{u}_X$​, and then applying the binscatter method to these residuals:\n\n$$\\bar{\\hat{u}}_{Y,k} = \\frac{1}{|B_k|} \\sum_{i \\in B_k} \\hat{u}_{X,i}.$$\n\nWhile this approach is motivated by the [Frisch-Waugh-Lovell](https://en.wikipedia.org/wiki/Frisch%E2%80%93Waugh%E2%80%93Lovell_theorem) theorem in linear regression, it can lead to incorrect conclusions in more general settings. The residualized binscatter may not accurately reflect the true conditional mean function, especially if the underlying relationship is nonlinear. Therefore, it is generally not recommended for empirical work.\n\n### Adjusting for Covariates: The Right Way\n\nInstead, this should be done using a semi-parametric partially linear regression model. This is achieved by modeling the conditional mean function as\n\n$$Y = \\mu_0(X) + W \\gamma_0 + \\varepsilon,$$\n\nwhere $\\mu_0(X)$ captures the main effect of $X$, and $W' \\gamma_0$ adjusts for the influence of additional covariates. Rather than residualizing, we estimate $\\mu_0(X)$ using the least-squares approach:\n\n$$(\\hat{\\beta}, \\hat{\\gamma}) = \\arg\\min_{\\beta, \\gamma} \\sum (Y- b(X)' \\beta - W' \\gamma)^2,$$\n\nwhere $b(X)$ represents the binning basis functions. The final binscatter plot displays the estimated conditional mean function\n\n  $$\\hat{\\mu}(X_k) = b(X_k)' \\hat{\\beta}$$\n\nagainst $\\bar{X}_k$, ensuring a correct visualization of the relationship between $X$ and $Y$ after accounting for the covariates $W$.\n\n### Practical Considerations\n\nA key decision is the choice of the number of bins $K$. Too few bins can oversmooth the data, masking important features, while too many bins can lead to undersmoothing, resulting in a noisy and less interpretable plot. An optimal choice of $K$ balances bias and variance, often determined using data-driven methods. To address this, [Cattaneo et al. (2024)](https://www.aeaweb.org/articles?id=10.1257/aer.20221576) propose an adaptive, Integrated Mean Squared Error (IMSE)-optimal choice of $K$ for which get a plug-in formula.\n\nThoughtful data scientist always have variance in their mind. If, for instance, we see some linear relationship between $Y$ and $X$, how can we determine whether it is statistically significant? Quantifying the uncertainty around binscatter estimates is crucial. The authors also discuss constructing confidence bands, which can be added to the plot to visually represent estimation uncertainty, enhancing both interpretability and reliability.\n\n## An Example\n\nAs an example let’s examine the relationship between the variables `Sepal.Length` and `Petal.Length` in the popular iris dataset. We will use a fixed number of ten bins. Alternatively, the package `binsreg` will automatically calculate the optimal $K$.\n\n::: {.panel-tabset}\n\n## R\n\n```r\n# clear the workspace and load libraries\nrm(list=ls())\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(binsreg)\ndata(iris)\n\n# define the number of bins\nbins <- 10\n\n# create binned data\niris_binned <- iris %>%\n  mutate(bin = cut(Sepal.Length, breaks = bins, include.lowest = TRUE)) %>%\n  group_by(bin) %>%\n  summarize(\n    bin_mid = mean(as.numeric(as.character(bin))),\n    mean_petal_length = mean(Petal.Length)\n  )\n\n# Add a panel label for the raw scatter plot\niris_raw <- iris %>% \n    mutate(panel = \"1. Raw Scatter Plot\")\n\n# Add a panel label for the binned scatter plot\niris_binned <- iris_binned %>%\n  mutate(panel = \"2. Binned Scatter Plot\")\n\n# Combine raw and binned data into a single dataset for plotting\nplot_data <- bind_rows(\niris_raw %>% rename(x = Sepal.Length, y = Petal.Length),\n  iris_binned %>% rename(x = bin_mid, y = mean_petal_length)\n)\n\n# Create the plot\nggplot(plot_data, aes(x = x, y = y)) +\n  geom_point() +\n  facet_wrap(~ panel, scales = \"free_x\", ncol = 2) +\n  labs(title = \"Comparison of Raw and Binned Scatter Plots\",\n  x = \"Sepal Length\",\n  y = \"Petal Length\") +\n  theme_minimal()\n```\n\n## Python\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load the iris dataset\nfrom sklearn.datasets import load_iris\niris_data = load_iris(as_frame=True)\niris = iris_data['data']\niris.columns = ['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']\n\n# Number of bins\nbins = 10\n\n# Create binned data\niris['bin'] = pd.cut(iris['Sepal.Length'], bins=bins, include_lowest=True)\niris_binned = iris.groupby('bin').agg(\n    bin_mid=('Sepal.Length', lambda x: (x.min() + x.max()) / 2),\n    mean_petal_length=('Petal.Length', 'mean')\n).reset_index()\n\n# Add panel labels\niris_raw = iris[['Sepal.Length', 'Petal.Length']].copy()\niris_raw['panel'] = \"1. Raw Scatter Plot\"\n\niris_binned = iris_binned.rename(columns={'bin_mid': 'Sepal.Length', 'mean_petal_length': 'Petal.Length'})\niris_binned['panel'] = \"2. Binned Scatter Plot\"\n\n# Combine raw and binned data\nplot_data = pd.concat([iris_raw, iris_binned], ignore_index=True)\n\n# Plot\nsns.set_theme(style=\"whitegrid\")\nfig, axes = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n\n# Raw scatter plot\nsns.scatterplot(\n    data=plot_data[plot_data['panel'] == \"1. Raw Scatter Plot\"],\n    x='Sepal.Length', y='Petal.Length', ax=axes[0]\n)\naxes[0].set_title(\"1. Raw Scatter Plot\")\naxes[0].set_xlabel(\"Sepal Length\")\naxes[0].set_ylabel(\"Petal Length\")\n\n# Binned scatter plot\nsns.scatterplot(\n    data=plot_data[plot_data['panel'] == \"2. Binned Scatter Plot\"],\n    x='Sepal.Length', y='Petal.Length', ax=axes[1]\n)\naxes[1].set_title(\"2. Binned Scatter Plot\")\naxes[1].set_xlabel(\"Sepal Length\")\n\n# Adjust layout\nplt.suptitle(\"Comparison of Raw and Binned Scatter Plots\")\nplt.tight_layout()\nplt.show()\n```\n\n:::\n\nHere is the resulting image. The left scatter plot displays the raw data and the right one shows the binscatter. Binscatter removes some of the clutter and highlights the linear relationship more directly.\n\n![](../images/binscatter.png)\n\n## Bottom Line\n\n- Binscatter simplifies scatterplots by aggregating data into bins and plotting means.\n\n- It is a powerful tool for visualizing relationships in large or noisy datasets.\n\n- Conditional and residualized binscatter extend its utility to controlling for covariates.\n\n- While intuitive, binscatter is sensitive to binning choices and may obscure nuances.\n\n## Where to Learn More\n\nBoth papers cited below are relatively accessible and will answer your questions. Start with Starr and Goldfarb (2020).\n\n## References\n\nCattaneo, M. D., Crump, R. K., Farrell, M. H., & Feng, Y. (2024). On Binscatter Regressions. American Economic Review, 111(3), 718–748.\n\nStarr, E., & Goldfarb, B. (2020). Binned scatterplots: A simple tool to make research easier and better. Strategic Management Journal, 41(12), 2261-2274."},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../code/styles.css"],"toc":true,"filters":["code-insertion"],"output-file":"binscatter.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.24","resources":["../code/open-links-new-tab.js","../code/back-to-top.js"],"theme":{"light":"cosmo","dark":"cyborg"},"header-includes":["<script type='text/javascript' src='https://platform-api.sharethis.com/js/sharethis.js#property=680ee8d89f7a510019a96bcf&product=inline-share-buttons' async='async'></script>\n<script src=\"../code/open-links-new-tab.js\"></script>  \n<script src=\"../code/back-to-top.js\"></script>\n<link href=\"https://fonts.googleapis.com/css2?family=Fira+Code&family=Source+Code+Pro&display=swap\" rel=\"stylesheet\">\n"],"page-layout":"full","includes":{"after-body":["../_includes/comments.html",{"text":"<button id=\"back-to-top\" onclick=\"scrollToTop()\">↑</button>\n"}]},"insert-before-post":"_sharebuttons.md","title":"Binscatter: A New Visual Tool for Data Analysis","date":"2025-02-09","categories":["correlation"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}