{"title":"Why Are Some Confidence Intervals Not Symmetric?","markdown":{"yaml":{"title":"Why Are Some Confidence Intervals Not Symmetric?","date":"2025-04-24","categories":["statistical inference","confidence intervals"]},"headingText":"Background","containsRefs":false,"markdown":"\n\n\nIf you’ve ever looked at a confidence interval and thought, “Huh, that’s weird—it’s not centered around the estimate,” you’re not alone. Many data scientists are used to the idea that a $95\\%$ confidence interval looks like estimate $\\pm$ margin of error. And that’s often true—especially for things like means from large samples, where the normal approximation kicks in. But it’s not always the case.\n\nIn this post, we’ll look at why some confidence intervals are asymmetric, what causes the skew, and when to expect this behavior. We'll also see how different methods (and different data!) can lead to intervals that don't look like what we might expect from a simple $t$-test.\n\n## Notation\n\nLet’s say we have a parameter $\\theta$ that we want to estimate, and we compute an estimator $\\hat{\\theta}$ from data. A $(1−\\alpha)$ confidence interval is an interval $[L,U]$ such that:\n\n$$P(L\\leq \\theta \\leq U) \\geq 1-\\alpha.$$\n\nIf $\\hat{\\theta}$ is symmetric and normally distributed, this confidence interval will typically be of the form:\n\n$$ \\hat{\\theta} \\pm z_{\\frac{\\alpha}{2}} \\times SE(\\hat{\\theta}),$$\n\nwhere $z_{\\frac{\\alpha}{2}}$ is called \"critical value\" (often equal to $1.96$). But things get more interesting—and more asymmetric—when the distribution of  is skewed, bounded, or derived from a nonlinear transformation.\n\n## A Closer Look\n\n### Simple Example: Proportion Near 0 or 1\n\nSuppose you're estimating a proportion $p$, like the rate of success in a small sample. If $p$ is close to $0$, the distribution of $\\hat{p}$  is skewed, and the Wald confidence interval (the usual $\\pm$$ formula) can produce nonsense—like a lower bound less than $0$.\n\nInstead, intervals based on the logit or Wilson score can be asymmetric. This is because the underlying transformation (like log-odds) isn't symmetric in $p$.\n\n### Why Intervals Get Skewed\n\nHere are some reasons why confidence intervals might be asymmetric:\n\n- **Skewed sampling distribution**: Common when estimating quantities like variance or proportions near the boundaries.\n\n- **Nonlinear transformations**: If your estimator is transformed (like $log(\\hat{\\theta})$ or $\\frac{1}{\\hat{\\theta}}$), the resulting CI will not be symmetric in $\\hat{\\theta}$.\n\n- **Boundary constraints**: If the parameter lies on $[0,1]$ or must be positive, then symmetric intervals may include impossible values.\n\n- **Bootstrap methods**: Percentile bootstrap intervals often yield asymmetric CIs because they use the empirical quantiles of a skewed sampling distribution.\n\n- **Maximum likelihood estimation**: Asymptotic normality applies, but in small samples or near boundaries, the intervals can be skewed.\n\n### Bootstrap Percentile Example\n\nLet’s illustrate this with a small example using a skewed distribution.\n\n:::: {.panel-tabset}\n\n### R\n\n```r\nset.seed(1982)\nx <- rexp(50, rate = 1)  # Exponential distribution\nboot_means <- replicate(1000, mean(sample(x, replace = TRUE)))\nquantile(boot_means, c(0.025, 0.975))  # Asymmetric CI\n```\n\n### Python\n\n```python\nimport numpy as np\nnp.random.seed(42)\nx = np.random.exponential(scale=1.0, size=50)\nboot_means = [np.mean(np.random.choice(x, size=50, replace=True)) for _ in range(1000)]\nnp.percentile(boot_means, [2.5, 97.5])  # Asymmetric CI\n```\n\n::::\n\nIn both cases, you’ll likely see that the CI is skewed—because the sampling distribution of the mean is skewed, especially with small samples from an exponential distribution.\n\nLet's expand on the exponential distribution example to demonstrate exactly how much asymmetry can appear in confidence intervals. The exponential distribution is right-skewed, making it perfect for illustrating asymmetric intervals.\n\n:::: {.panel-tabset}\n\n\n### R\n\n```r\n# Set seed for reproducibility\nset.seed(1982)\n\n# Generate 50 observations from an exponential distribution\nx <- rexp(50, rate = 1)\n\n# Calculate the sample mean\nsample_mean <- mean(x)\n\n# Generate 10,000 bootstrap samples and calculate means\nboot_means <- replicate(10000, mean(sample(x, replace = TRUE)))\n\n# Calculate the percentile-based 95% confidence interval\nci_percentile <- quantile(boot_means, c(0.025, 0.975))\n\n# Calculate how far each bound is from the point estimate\nlower_distance <- sample_mean - ci_percentile[1]\nupper_distance <- ci_percentile[2] - sample_mean\n\n# for comparison - Symmetric 95% CI using normal approximation\nse <- sd(x) / sqrt(length(x))\nci_symmetric <- c(sample_mean - 1.96*se, sample_mean + 1.96*se)\n```\n\n### Python\n\n```python\nimport numpy as np\n\n# Set seed for reproducibility\nnp.random.seed(1982)\n\n# Generate 50 observations from an exponential distribution\nx = np.random.exponential(scale=1.0, size=50)\n\n# Calculate the sample mean\nsample_mean = np.mean(x)\n\n# Generate 10,000 bootstrap samples and calculate means\nboot_means = [np.mean(np.random.choice(x, size=50, replace=True)) for _ in range(10000)]\n\n# Calculate the percentile-based 95% confidence interval\nci_percentile = np.percentile(boot_means, [2.5, 97.5])\n\n# Calculate how far each bound is from the point estimate\nlower_distance = sample_mean - ci_percentile[0]\nupper_distance = ci_percentile[1] - sample_mean\n\n# For comparison - Symmetric 95% CI using normal approximation\nse = np.std(x, ddof=1) / np.sqrt(len(x))\nci_symmetric = [sample_mean - 1.96 * se, sample_mean + 1.96 * se]\n\n# Print results\nprint(\"Sample Mean:\", sample_mean)\nprint(\"Percentile-based 95% CI:\", ci_percentile)\nprint(\"Lower Distance:\", lower_distance)\nprint(\"Upper Distance:\", upper_distance)\nprint(\"Symmetric 95% CI:\", ci_symmetric)\n```\n\n::::\n\nAs we can see, the confidence interval extends 0.23 units below the mean but 0.27 units above it - the upper bound is about 17% further from the mean than the lower bound. This asymmetry directly reflects the right-skewed nature of the exponential distribution's sampling distribution.\n\nThis numerical example demonstrates that with skewed data, the distance from the point estimate to the lower bound can differ substantially from the distance to the upper bound. When reporting results, acknowledging this asymmetry provides a more accurate representation of the uncertainty in your estimate than simply reporting \"estimate ± margin of error.\"\nThe degree of asymmetry often depends on both the sample size and the underlying distribution - with smaller samples from more skewed distributions showing greater asymmetry in their confidence intervals.\n\n## Bottom Line\n\n- Symmetric confidence intervals come from symmetric distributions—don’t expect them when that’s not the case.\n\n- Asymmetric intervals are common with proportions, skewed data, nonlinear functions, and bootstrap methods.\n\n- Always check if your CI method makes assumptions about symmetry or normality.\n\n- Don’t blindly use $\\pm$ formulas—there are better (and more honest) ways to quantify uncertainty.\n\n# Where to Learn More\n\nFor an intuitive yet technical introduction, Statistical Inference by Casella and Berger covers the theory behind these intervals. For practical applications, especially bootstrap-based intervals, Efron and Tibshirani’s An Introduction to the Bootstrap is excellent. If you’re more into Bayesian approaches, check out Gelman et al.’s Bayesian Data Analysis—it shows how posterior distributions naturally yield asymmetric intervals when appropriate.\n\n## References\n\nEfron, B., & Tibshirani, R. J. (1993). An Introduction to the Bootstrap.\n\nCasella, G., & Berger, R. L. (2002). Statistical Inference.\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis.","srcMarkdownNoYaml":"\n\n## Background\n\nIf you’ve ever looked at a confidence interval and thought, “Huh, that’s weird—it’s not centered around the estimate,” you’re not alone. Many data scientists are used to the idea that a $95\\%$ confidence interval looks like estimate $\\pm$ margin of error. And that’s often true—especially for things like means from large samples, where the normal approximation kicks in. But it’s not always the case.\n\nIn this post, we’ll look at why some confidence intervals are asymmetric, what causes the skew, and when to expect this behavior. We'll also see how different methods (and different data!) can lead to intervals that don't look like what we might expect from a simple $t$-test.\n\n## Notation\n\nLet’s say we have a parameter $\\theta$ that we want to estimate, and we compute an estimator $\\hat{\\theta}$ from data. A $(1−\\alpha)$ confidence interval is an interval $[L,U]$ such that:\n\n$$P(L\\leq \\theta \\leq U) \\geq 1-\\alpha.$$\n\nIf $\\hat{\\theta}$ is symmetric and normally distributed, this confidence interval will typically be of the form:\n\n$$ \\hat{\\theta} \\pm z_{\\frac{\\alpha}{2}} \\times SE(\\hat{\\theta}),$$\n\nwhere $z_{\\frac{\\alpha}{2}}$ is called \"critical value\" (often equal to $1.96$). But things get more interesting—and more asymmetric—when the distribution of  is skewed, bounded, or derived from a nonlinear transformation.\n\n## A Closer Look\n\n### Simple Example: Proportion Near 0 or 1\n\nSuppose you're estimating a proportion $p$, like the rate of success in a small sample. If $p$ is close to $0$, the distribution of $\\hat{p}$  is skewed, and the Wald confidence interval (the usual $\\pm$$ formula) can produce nonsense—like a lower bound less than $0$.\n\nInstead, intervals based on the logit or Wilson score can be asymmetric. This is because the underlying transformation (like log-odds) isn't symmetric in $p$.\n\n### Why Intervals Get Skewed\n\nHere are some reasons why confidence intervals might be asymmetric:\n\n- **Skewed sampling distribution**: Common when estimating quantities like variance or proportions near the boundaries.\n\n- **Nonlinear transformations**: If your estimator is transformed (like $log(\\hat{\\theta})$ or $\\frac{1}{\\hat{\\theta}}$), the resulting CI will not be symmetric in $\\hat{\\theta}$.\n\n- **Boundary constraints**: If the parameter lies on $[0,1]$ or must be positive, then symmetric intervals may include impossible values.\n\n- **Bootstrap methods**: Percentile bootstrap intervals often yield asymmetric CIs because they use the empirical quantiles of a skewed sampling distribution.\n\n- **Maximum likelihood estimation**: Asymptotic normality applies, but in small samples or near boundaries, the intervals can be skewed.\n\n### Bootstrap Percentile Example\n\nLet’s illustrate this with a small example using a skewed distribution.\n\n:::: {.panel-tabset}\n\n### R\n\n```r\nset.seed(1982)\nx <- rexp(50, rate = 1)  # Exponential distribution\nboot_means <- replicate(1000, mean(sample(x, replace = TRUE)))\nquantile(boot_means, c(0.025, 0.975))  # Asymmetric CI\n```\n\n### Python\n\n```python\nimport numpy as np\nnp.random.seed(42)\nx = np.random.exponential(scale=1.0, size=50)\nboot_means = [np.mean(np.random.choice(x, size=50, replace=True)) for _ in range(1000)]\nnp.percentile(boot_means, [2.5, 97.5])  # Asymmetric CI\n```\n\n::::\n\nIn both cases, you’ll likely see that the CI is skewed—because the sampling distribution of the mean is skewed, especially with small samples from an exponential distribution.\n\nLet's expand on the exponential distribution example to demonstrate exactly how much asymmetry can appear in confidence intervals. The exponential distribution is right-skewed, making it perfect for illustrating asymmetric intervals.\n\n:::: {.panel-tabset}\n\n\n### R\n\n```r\n# Set seed for reproducibility\nset.seed(1982)\n\n# Generate 50 observations from an exponential distribution\nx <- rexp(50, rate = 1)\n\n# Calculate the sample mean\nsample_mean <- mean(x)\n\n# Generate 10,000 bootstrap samples and calculate means\nboot_means <- replicate(10000, mean(sample(x, replace = TRUE)))\n\n# Calculate the percentile-based 95% confidence interval\nci_percentile <- quantile(boot_means, c(0.025, 0.975))\n\n# Calculate how far each bound is from the point estimate\nlower_distance <- sample_mean - ci_percentile[1]\nupper_distance <- ci_percentile[2] - sample_mean\n\n# for comparison - Symmetric 95% CI using normal approximation\nse <- sd(x) / sqrt(length(x))\nci_symmetric <- c(sample_mean - 1.96*se, sample_mean + 1.96*se)\n```\n\n### Python\n\n```python\nimport numpy as np\n\n# Set seed for reproducibility\nnp.random.seed(1982)\n\n# Generate 50 observations from an exponential distribution\nx = np.random.exponential(scale=1.0, size=50)\n\n# Calculate the sample mean\nsample_mean = np.mean(x)\n\n# Generate 10,000 bootstrap samples and calculate means\nboot_means = [np.mean(np.random.choice(x, size=50, replace=True)) for _ in range(10000)]\n\n# Calculate the percentile-based 95% confidence interval\nci_percentile = np.percentile(boot_means, [2.5, 97.5])\n\n# Calculate how far each bound is from the point estimate\nlower_distance = sample_mean - ci_percentile[0]\nupper_distance = ci_percentile[1] - sample_mean\n\n# For comparison - Symmetric 95% CI using normal approximation\nse = np.std(x, ddof=1) / np.sqrt(len(x))\nci_symmetric = [sample_mean - 1.96 * se, sample_mean + 1.96 * se]\n\n# Print results\nprint(\"Sample Mean:\", sample_mean)\nprint(\"Percentile-based 95% CI:\", ci_percentile)\nprint(\"Lower Distance:\", lower_distance)\nprint(\"Upper Distance:\", upper_distance)\nprint(\"Symmetric 95% CI:\", ci_symmetric)\n```\n\n::::\n\nAs we can see, the confidence interval extends 0.23 units below the mean but 0.27 units above it - the upper bound is about 17% further from the mean than the lower bound. This asymmetry directly reflects the right-skewed nature of the exponential distribution's sampling distribution.\n\nThis numerical example demonstrates that with skewed data, the distance from the point estimate to the lower bound can differ substantially from the distance to the upper bound. When reporting results, acknowledging this asymmetry provides a more accurate representation of the uncertainty in your estimate than simply reporting \"estimate ± margin of error.\"\nThe degree of asymmetry often depends on both the sample size and the underlying distribution - with smaller samples from more skewed distributions showing greater asymmetry in their confidence intervals.\n\n## Bottom Line\n\n- Symmetric confidence intervals come from symmetric distributions—don’t expect them when that’s not the case.\n\n- Asymmetric intervals are common with proportions, skewed data, nonlinear functions, and bootstrap methods.\n\n- Always check if your CI method makes assumptions about symmetry or normality.\n\n- Don’t blindly use $\\pm$ formulas—there are better (and more honest) ways to quantify uncertainty.\n\n# Where to Learn More\n\nFor an intuitive yet technical introduction, Statistical Inference by Casella and Berger covers the theory behind these intervals. For practical applications, especially bootstrap-based intervals, Efron and Tibshirani’s An Introduction to the Bootstrap is excellent. If you’re more into Bayesian approaches, check out Gelman et al.’s Bayesian Data Analysis—it shows how posterior distributions naturally yield asymmetric intervals when appropriate.\n\n## References\n\nEfron, B., & Tibshirani, R. J. (1993). An Introduction to the Bootstrap.\n\nCasella, G., & Berger, R. L. (2002). Statistical Inference.\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis."},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../code/styles.css"],"toc":true,"include-in-header":[{"text":"<script src=\"../code/open-links-new-tab.js\"></script>\n"}],"output-file":"non-symmetric-conf-intervals.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.24","resources":["../code/open-links-new-tab.js"],"theme":{"light":"cosmo","dark":"cyborg"},"page-layout":"full","title":"Why Are Some Confidence Intervals Not Symmetric?","date":"2025-04-24","categories":["statistical inference","confidence intervals"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}