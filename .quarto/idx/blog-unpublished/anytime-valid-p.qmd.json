{"title":"Anytime-Valid $p$-values and Online Multiple Testing: A Modern Guide","markdown":{"yaml":{"title":"Anytime-Valid $p$-values and Online Multiple Testing: A Modern Guide","date":"2025-00-00","categories":["multiple testing","statistical inference"]},"headingText":"Background","containsRefs":false,"markdown":"\n\n\nIn modern data analysis, we often don’t test all hypotheses at once. Instead, hypotheses arrive over time: an A/B test today, another one tomorrow, and so on. The problem? Traditional multiple testing corrections like the Bonferroni or Benjamini-Hochberg procedures assume you know the total number of hypotheses *in advance*. They were designed for batch testing, not for this streaming world.\n\nThis mismatch has serious consequences. If you naively apply these classical corrections each time a new test arrives, you'll either inflate your false discovery rate (FDR) or make your tests overly conservative, wasting precious power. Worse yet, if you monitor your $p$-values as data accumulate and stop when they look good (a practice called *continuous monitoring* or *peeking*), traditional $p$-values are no longer valid.\n\nThis is where **anytime-valid $p$-values** and **online multiple testing methods** come to the rescue. They let you monitor and make decisions at any time, without inflating Type I errors — all while controlling error rates like the FDR.\n\nIn this article, we explain how anytime-valid inference works, why traditional $p$-values fail in online settings, and introduce the key algorithms developed over the last 15 years that allow principled, flexible testing when hypotheses arrive sequentially.\n\n## Notation\n\nAt time $t$, you face hypothesis $H_t$, with a $p$-value $P_t$. You must decide whether to reject $H_t$ before seeing $H_{t+1}$. Importantly:\n- You don't know how many hypotheses will arrive in total.\n- Your decision $R_t$ (reject or not) may depend on past decisions $R_1, \\dots, R_{t-1}$.\n\nThe **false discovery proportion (FDP)** at time $T$ is:\n\n$$\n\\text{FDP}(T) = \\frac{V(T)}{R(T) \\vee 1},\n$$\n\nwhere $V(T)$ is the number of false rejections and $R(T)$ is the total number of rejections. The **false discovery rate (FDR)** is the expectation of this quantity:\n\n$$\n\\text{FDR}(T) = \\mathbb{E}\\left[ \\frac{V(T)}{R(T) \\vee 1} \\right].\n$$\n\nAn **anytime-valid $p$-value** is a $p$-value that remains valid no matter when you stop — even if you peek at the data continuously.\n\n## A Closer Look\n\n### Why Traditional $p$-values Fail in Sequential Testing\n\nTraditional $p$-values assume a fixed sample size and no interim monitoring. If you check the $p$-value repeatedly and stop as soon as it crosses a threshold, you're implicitly running a sequential test without adjusting for multiple looks.\n\nThis leads to **inflated Type I error rates** because the chance of eventually seeing a small $p$-value grows with each additional look. The $p$-value you see is no longer uniformly distributed under the null.\n\nAnytime-valid $p$-values solve this by ensuring validity at every possible stopping time. Formally, for any stopping rule $N$:\n\n$$\n\\Pr(P_{t, N} \\leq x) \\leq x \\quad \\text{for all } x \\in [0,1].\n$$\n\n### The Rise of Online Multiple Testing\n\nOnce we have anytime-valid $p$-values, we can build **online multiple testing procedures** that control the FDR over time. Here, you never know the total number of hypotheses upfront — hypotheses just keep arriving.\n\nThe pioneering work of Foster and Stine (2008) introduced the concept of **alpha-investing**, a method that allocates an \"alpha-wealth\" budget across tests. Rejections replenish this budget, allowing more liberal testing when discoveries accumulate.\n\nSubsequent work refined these ideas into powerful modern algorithms:\n\n#### 1. **LORD++** (Javanmard and Montanari, Ramdas et al.)\nLORD++ stands for **Levels based On Recent Discovery**, a monotone GAI++ (Generalized Alpha Investing) rule. It updates testing levels dynamically based on previous rejections, preventing the test levels from collapsing as more tests accumulate.\n\n#### 2. **SAFFRON** (Ramdas et al., 2018)\nAn adaptive procedure that estimates the proportion of null hypotheses and avoids wasting testing budget on weak signals. SAFFRON focuses alpha-wealth on promising $p$-values, improving power especially when there are many non-nulls.\n\n#### 3. **ADDIS** (Tian and Ramdas, 2019)\nADDIS stands for **ADaptive algorithm that DIScards conservative nulls**. It further improves power by discarding $p$-values that are unlikely to be rejected anyway (e.g., large $p$-values that suggest conservative nulls).\n\n### Anytime-valid $p$-values and Confidence Sequences\n\nAnytime-valid $p$-values often arise from **confidence sequences** — time-uniform confidence intervals that hold at every sample size. These are built using techniques like:\n\n- **Martingale-based betting strategies** (e.g., e-processes).\n- **Concentration inequalities** (e.g., Hoeffding's inequality for bounded data).\n\nFor example, in A/B testing, always-valid $p$-values allow you to continuously monitor the success rate difference between two groups without inflating your Type I error.\n\n## Bottom Line\n\n- Traditional $p$-values are not valid under continuous monitoring or online testing.\n\n- Anytime-valid $p$-values remain valid no matter when you stop.\n\n- Online multiple testing algorithms like LORD++, SAFFRON, and ADDIS enable FDR control when hypotheses arrive sequentially.\n\n- Adaptive algorithms improve power by estimating the fraction of nulls and focusing resources on likely non-nulls.\n\n## Where to Learn More\n\nThe paper by Robertson, Wason, and Ramdas (2023) offers an excellent review of the literature on online error rate control, including algorithmic details, proofs, and simulation results. For a deep dive into anytime-valid $p$-values and confidence sequences, see Howard et al. (2021) and the always-valid inference literature.\n\n## References\n\n- Robertson, D. S., Wason, J. M. S., & Ramdas, A. (2023). Online Multiple Hypothesis Testing. *Statistical Science*, 38(4), 557–575.\n\n- Foster, D. P., & Stine, R. A. (2008). Alpha-Investing: A Procedure for Sequential Control of Expected False Discoveries. *Journal of the Royal Statistical Society: Series B*, 70(2), 429–444.\n\n- Ramdas, A., et al. (2018). SAFFRON: An Adaptive Algorithm for Online Control of the False Discovery Rate. *Journal of the Royal Statistical Society: Series B*, 80(5), 1225–1248.\n\n- Tian, J., & Ramdas, A. (2019). ADDIS: An Adaptive Discarding Algorithm for Online FDR Control. *International Conference on Artificial Intelligence and Statistics (AISTATS)*.\n\n- Howard, S. R., Ramdas, A., McAuliffe, J. D., & Sekhon, J. S. (2021). Time-Uniform Chernoff Bounds via Nonnegative Supermartingales. *Probability Surveys*, 18, 1–29.\n","srcMarkdownNoYaml":"\n\n## Background\n\nIn modern data analysis, we often don’t test all hypotheses at once. Instead, hypotheses arrive over time: an A/B test today, another one tomorrow, and so on. The problem? Traditional multiple testing corrections like the Bonferroni or Benjamini-Hochberg procedures assume you know the total number of hypotheses *in advance*. They were designed for batch testing, not for this streaming world.\n\nThis mismatch has serious consequences. If you naively apply these classical corrections each time a new test arrives, you'll either inflate your false discovery rate (FDR) or make your tests overly conservative, wasting precious power. Worse yet, if you monitor your $p$-values as data accumulate and stop when they look good (a practice called *continuous monitoring* or *peeking*), traditional $p$-values are no longer valid.\n\nThis is where **anytime-valid $p$-values** and **online multiple testing methods** come to the rescue. They let you monitor and make decisions at any time, without inflating Type I errors — all while controlling error rates like the FDR.\n\nIn this article, we explain how anytime-valid inference works, why traditional $p$-values fail in online settings, and introduce the key algorithms developed over the last 15 years that allow principled, flexible testing when hypotheses arrive sequentially.\n\n## Notation\n\nAt time $t$, you face hypothesis $H_t$, with a $p$-value $P_t$. You must decide whether to reject $H_t$ before seeing $H_{t+1}$. Importantly:\n- You don't know how many hypotheses will arrive in total.\n- Your decision $R_t$ (reject or not) may depend on past decisions $R_1, \\dots, R_{t-1}$.\n\nThe **false discovery proportion (FDP)** at time $T$ is:\n\n$$\n\\text{FDP}(T) = \\frac{V(T)}{R(T) \\vee 1},\n$$\n\nwhere $V(T)$ is the number of false rejections and $R(T)$ is the total number of rejections. The **false discovery rate (FDR)** is the expectation of this quantity:\n\n$$\n\\text{FDR}(T) = \\mathbb{E}\\left[ \\frac{V(T)}{R(T) \\vee 1} \\right].\n$$\n\nAn **anytime-valid $p$-value** is a $p$-value that remains valid no matter when you stop — even if you peek at the data continuously.\n\n## A Closer Look\n\n### Why Traditional $p$-values Fail in Sequential Testing\n\nTraditional $p$-values assume a fixed sample size and no interim monitoring. If you check the $p$-value repeatedly and stop as soon as it crosses a threshold, you're implicitly running a sequential test without adjusting for multiple looks.\n\nThis leads to **inflated Type I error rates** because the chance of eventually seeing a small $p$-value grows with each additional look. The $p$-value you see is no longer uniformly distributed under the null.\n\nAnytime-valid $p$-values solve this by ensuring validity at every possible stopping time. Formally, for any stopping rule $N$:\n\n$$\n\\Pr(P_{t, N} \\leq x) \\leq x \\quad \\text{for all } x \\in [0,1].\n$$\n\n### The Rise of Online Multiple Testing\n\nOnce we have anytime-valid $p$-values, we can build **online multiple testing procedures** that control the FDR over time. Here, you never know the total number of hypotheses upfront — hypotheses just keep arriving.\n\nThe pioneering work of Foster and Stine (2008) introduced the concept of **alpha-investing**, a method that allocates an \"alpha-wealth\" budget across tests. Rejections replenish this budget, allowing more liberal testing when discoveries accumulate.\n\nSubsequent work refined these ideas into powerful modern algorithms:\n\n#### 1. **LORD++** (Javanmard and Montanari, Ramdas et al.)\nLORD++ stands for **Levels based On Recent Discovery**, a monotone GAI++ (Generalized Alpha Investing) rule. It updates testing levels dynamically based on previous rejections, preventing the test levels from collapsing as more tests accumulate.\n\n#### 2. **SAFFRON** (Ramdas et al., 2018)\nAn adaptive procedure that estimates the proportion of null hypotheses and avoids wasting testing budget on weak signals. SAFFRON focuses alpha-wealth on promising $p$-values, improving power especially when there are many non-nulls.\n\n#### 3. **ADDIS** (Tian and Ramdas, 2019)\nADDIS stands for **ADaptive algorithm that DIScards conservative nulls**. It further improves power by discarding $p$-values that are unlikely to be rejected anyway (e.g., large $p$-values that suggest conservative nulls).\n\n### Anytime-valid $p$-values and Confidence Sequences\n\nAnytime-valid $p$-values often arise from **confidence sequences** — time-uniform confidence intervals that hold at every sample size. These are built using techniques like:\n\n- **Martingale-based betting strategies** (e.g., e-processes).\n- **Concentration inequalities** (e.g., Hoeffding's inequality for bounded data).\n\nFor example, in A/B testing, always-valid $p$-values allow you to continuously monitor the success rate difference between two groups without inflating your Type I error.\n\n## Bottom Line\n\n- Traditional $p$-values are not valid under continuous monitoring or online testing.\n\n- Anytime-valid $p$-values remain valid no matter when you stop.\n\n- Online multiple testing algorithms like LORD++, SAFFRON, and ADDIS enable FDR control when hypotheses arrive sequentially.\n\n- Adaptive algorithms improve power by estimating the fraction of nulls and focusing resources on likely non-nulls.\n\n## Where to Learn More\n\nThe paper by Robertson, Wason, and Ramdas (2023) offers an excellent review of the literature on online error rate control, including algorithmic details, proofs, and simulation results. For a deep dive into anytime-valid $p$-values and confidence sequences, see Howard et al. (2021) and the always-valid inference literature.\n\n## References\n\n- Robertson, D. S., Wason, J. M. S., & Ramdas, A. (2023). Online Multiple Hypothesis Testing. *Statistical Science*, 38(4), 557–575.\n\n- Foster, D. P., & Stine, R. A. (2008). Alpha-Investing: A Procedure for Sequential Control of Expected False Discoveries. *Journal of the Royal Statistical Society: Series B*, 70(2), 429–444.\n\n- Ramdas, A., et al. (2018). SAFFRON: An Adaptive Algorithm for Online Control of the False Discovery Rate. *Journal of the Royal Statistical Society: Series B*, 80(5), 1225–1248.\n\n- Tian, J., & Ramdas, A. (2019). ADDIS: An Adaptive Discarding Algorithm for Online FDR Control. *International Conference on Artificial Intelligence and Statistics (AISTATS)*.\n\n- Howard, S. R., Ramdas, A., McAuliffe, J. D., & Sekhon, J. S. (2021). Time-Uniform Chernoff Bounds via Nonnegative Supermartingales. *Probability Surveys*, 18, 1–29.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../code/styles.css"],"toc":true,"include-in-header":[{"text":"<script src=\"../code/open-links-new-tab.js\"></script>\n"}],"output-file":"anytime-valid-p.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.24","resources":["../code/open-links-new-tab.js"],"theme":{"light":"cosmo","dark":"cyborg"},"page-layout":"full","title":"Anytime-Valid $p$-values and Online Multiple Testing: A Modern Guide","date":"2025-00-00","categories":["multiple testing","statistical inference"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}