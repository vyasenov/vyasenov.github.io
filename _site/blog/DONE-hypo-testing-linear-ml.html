<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.24">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2022-11-06">

<title>Hypothesis Testing in Linear Machine Learning Models – Vasco Yasenov</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-1e438c382a17f6d88d3993662a872df6.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-a37c72dd2dbac68997fcdc15a3622e78.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-c1fac2584b48ed01fb6e278e36375074.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-a9957ab5e8b7c67643b7e2e6b5c1e54e.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../site_libs/bootstrap/bootstrap-c1fac2584b48ed01fb6e278e36375074.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    window.setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      window.setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    window.hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(darkModeDefault) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const darkModeDefault = false;
    document.querySelector('link.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !window.hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
    };
    // Switch to dark mode if need be
    if (window.hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Vasco Yasenov</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../cv.html"> 
<span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../blog/index.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../research.html"> 
<span class="menu-text">Research</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../childrenbook.html"> 
<span class="menu-text">Children’s Book</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/vyasenov" target="_blank"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/vasil-yasenov/" target="_blank"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://scholar.google.com/citations?user=pQw1oG8AAAAJ" target="_blank"> <i class="bi bi-mortarboard-fill" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.amazon.com/Causal-Inference-Toddlers-Meatball-Recipe/dp/B0BLG6SWZJ" target="_blank"> <i class="bi bi-amazon" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#background" id="toc-background" class="nav-link active" data-scroll-target="#background">Background</a></li>
  <li><a href="#notation" id="toc-notation" class="nav-link" data-scroll-target="#notation">Notation</a></li>
  <li><a href="#a-closer-look" id="toc-a-closer-look" class="nav-link" data-scroll-target="#a-closer-look">A Closer Look</a>
  <ul class="collapse">
  <li><a href="#two-types-of-models-and-parameters" id="toc-two-types-of-models-and-parameters" class="nav-link" data-scroll-target="#two-types-of-models-and-parameters">Two Types of Models and Parameters</a></li>
  <li><a href="#the-naïve-approach-what-not-to-do" id="toc-the-naïve-approach-what-not-to-do" class="nav-link" data-scroll-target="#the-naïve-approach-what-not-to-do">The Naïve Approach: What <em>Not</em> to Do</a></li>
  <li><a href="#the-classical-approach-inference-on-the-full-model" id="toc-the-classical-approach-inference-on-the-full-model" class="nav-link" data-scroll-target="#the-classical-approach-inference-on-the-full-model">The Classical Approach: Inference on the Full Model</a></li>
  <li><a href="#the-novel-approach-inference-on-the-selected-model" id="toc-the-novel-approach-inference-on-the-selected-model" class="nav-link" data-scroll-target="#the-novel-approach-inference-on-the-selected-model">The Novel Approach: Inference on the Selected Model</a></li>
  </ul></li>
  <li><a href="#an-example" id="toc-an-example" class="nav-link" data-scroll-target="#an-example">An Example</a></li>
  <li><a href="#bottom-line" id="toc-bottom-line" class="nav-link" data-scroll-target="#bottom-line">Bottom Line</a></li>
  <li><a href="#where-to-learn-more" id="toc-where-to-learn-more" class="nav-link" data-scroll-target="#where-to-learn-more">Where to Learn More</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Hypothesis Testing in Linear Machine Learning Models</h1>
  <div class="quarto-categories">
    <div class="quarto-category">hypothesis testing</div>
    <div class="quarto-category">machine learning</div>
  </div>
  </div>



<div class="quarto-title-meta column-page-left">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 6, 2022</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>Machine learning models are an indispensable part of data science. They are incredibly good at what they are designed for – making excellent predictions. They fall short in assessing the strength of the relationships they find. ML models make no reference to hypothesis testing, p-values, or anything else related to statistical significance. Why?</p>
<p>Several thorny challenges stand in the way. For starters, ML algorithms often scan the data multiple times to choose the best model (e.g., in selecting hyperparameters or choosing a few relevant variables). In the world of statistical inference, this is a bit like cheating since we have <em>already</em> selected the most strongly correlated variables.</p>
<p>Even if we can account for this (which we sometimes can), there is still the issue that ML models might make mistakes. For instance, regularization might force a model to exclude a variable that, in reality, belongs to the model with only a small coefficient. The <span class="math inline">\(t\)</span>-stats and <span class="math inline">\(p\)</span>-values of the remaining variables are potentially contaminated and unreliable. This might seem subtle, but overcoming it has proven challenging.</p>
<p>Researchers have made significant progress in assessing statistical significance in ML models in the past decade. This is exciting as it widens our understanding of how these so-very-commonly-used models work. We now have a wide variety of methods for hypothesis testing, and I will walk you through some of the most popular ones.</p>
<p>This field is often referred to as statistical inference after model selection. For simplicity, I will focus on linear models (and Lasso in particular), where we have the most exciting breakthroughs. Keep in mind that many methods generalize to other linear models – Ridge, Elastic net, SCAD, etc.</p>
</section>
<section id="notation" class="level2">
<h2 class="anchored" data-anchor-id="notation">Notation</h2>
<p>As a reminder, <span class="math inline">\(\beta^{lasso}\)</span> is the solution to:</p>
<p><span class="math display">\[\min_{\beta} \frac{1}{2} || Y-x\beta|| ^2_2 + \lambda ||\beta||_1. \]</span></p>
<p>We are trying to predict a vector <span class="math inline">\(Y\in \mathbb{R}\)</span> with a set of features <span class="math inline">\(X\in \mathbb{R}^{pxn}\)</span> with <span class="math inline">\(p\leq n\)</span>, and <span class="math inline">\(\lambda\)</span> is a tuning parameter. When needed, I will use <span class="math inline">\(j\)</span> to index individual columns (i.e., variables) of <span class="math inline">\(X\)</span>.</p>
</section>
<section id="a-closer-look" class="level2">
<h2 class="anchored" data-anchor-id="a-closer-look">A Closer Look</h2>
<section id="two-types-of-models-and-parameters" class="level3">
<h3 class="anchored" data-anchor-id="two-types-of-models-and-parameters">Two Types of Models and Parameters</h3>
<p>We first need to discuss an important subtlety. There are two distinct ways of thinking about performing hypothesis testing in ML models. The traditional view is that we have a true linear model which includes all variables:</p>
<p><span class="math display">\[\begin{equation} Y=X\beta_0+\epsilon. \end{equation}\]</span></p>
<p>We are interested in testing whether <span class="math inline">\(\beta_0=0\)</span> – that is, inference on the full model. This is certainly an intuitive target. The interpretation is that this model encapsulates all relevant causal variables for <span class="math inline">\(Y\)</span>. Importantly, even if a given variable $X_j $ is not selected, it still belongs to the model and has a meaningful interpretation.</p>
<p>There is an alternative way to think about the problem. Imagine we run a variable selection algorithm (e.g., lasso), which selects a subset <span class="math inline">\(M=\{1,\dots,p\}\)</span> of all available predictors (<span class="math inline">\(X\)</span>), <span class="math inline">\(M&lt;p\)</span> leading to the alternative model:</p>
<p><span class="math display">\[\begin{equation} Y=X_M\beta_M+u. \end{equation}\]</span></p>
<p>Now we are interested in testing whether <span class="math inline">\(\beta_M=0\)</span> – that is, inference on the selected model. Unlike the scenario above, here <span class="math inline">\(\beta_{Mj}\)</span> is interpreted as the change in <span class="math inline">\(Y\)</span> for a unit change in <span class="math inline">\(X_j\)</span> when all other variables in <span class="math inline">\(X_M\)</span> (as opposed to all of <span class="math inline">\(X\)</span>) are kept constant.</p>
<p>Which of the two targets is more intuitive?</p>
<p>Statisticians argue vehemently about this. Some claim that the full model interpretation is inherently problematic. It is too naïve and perhaps even arrogant to think that (<em>i</em>) mother nature can be explained by a linear equation, (<em>ii</em>) we can measure and include the full set of relevant predictors. On top of this, there are also <a href="https://doi.org/10.1017/S0266466605050036">technical issues</a> with this interpretation beyond the scope of this post.</p>
<p>To overcome these challenges, relatively recently, statisticians developed the idea of inference on the selected model. This introduces major technical challenges, however.</p>
</section>
<section id="the-naïve-approach-what-not-to-do" class="level3">
<h3 class="anchored" data-anchor-id="the-naïve-approach-what-not-to-do">The Naïve Approach: What <em>Not</em> to Do</h3>
<p>First things first – here is what we should not do.</p>
<ol type="1">
<li>Run a Lasso regression.</li>
<li>Run OLS regression on the subset of selected variables.</li>
<li>Perform statistical inference with the estimated t-stats, confidence intervals, and p-values.</li>
</ol>
<p>This is bad practice. Can you see why?</p>
<p>It is simply because we ignored the fact that we already peeked at the data when we ran the Lasso regression. Lasso already chose the variables that are strongly correlated with the outcome. Intuitively, we will need to inflate the <span class="math inline">\(p\)</span>-values to account for the data exploration in the first step.</p>
<p>It <a href="https://doi.org/10.1017/S0266466605050036">turns out</a> that, in general, both the finite- and large-sample distributions of these parameters are non-Gaussian and depend on unknown parameters in weird ways. Consequently, the calculated t-stats and p-values are all wrong, and there is little hope that anything simple can be done to save this approach. And no, the standard bootstrap cannot help us either.</p>
<p>But are there special cases when this approach might work? A recent paper titled “<em><a href="https://projecteuclid.org/journals/statistical-science/volume-36/issue-4/In-Defense-of-the-Indefensible--A-Very-Na%C3%AFve-Approach/10.1214/20-STS815.short">In Defense of the Indefensible</a>: A Very Naïve Approach to High-Dimensional Inference</em>” argues that under very strict assumptions on <span class="math inline">\(X\)</span> and <span class="math inline">\(\lambda\)</span>, this method is actually kosher. The reason it works is that in the magical world of those assumptions, the set of variables that Lasso chooses is deterministic, and not random (hence circumventing the issue described above). The resulting estimator is unbiased and asymptotically normal – hence hypothesis testing is trivial.</p>
<p>Here is what we should do instead.</p>
</section>
<section id="the-classical-approach-inference-on-the-full-model" class="level3">
<h3 class="anchored" data-anchor-id="the-classical-approach-inference-on-the-full-model">The Classical Approach: Inference on the Full Model</h3>
<p>Roughly speaking, there are at least four ways we can go about doing hypothesis testing for <span class="math inline">\(\beta\)</span> in equation (1).</p>
<section id="data-split" class="level4">
<h4 class="anchored" data-anchor-id="data-split">Data Split</h4>
<ol type="1">
<li>Split our data into two equal parts.</li>
<li>Run a Lasso regression on the first part.</li>
<li>Run OLS on the second part with the selected variables from Step 2.</li>
<li>Perform inference using the computed <span class="math inline">\(t\)</span>-stats, <span class="math inline">\(p\)</span>-values, and confidence intervals.</li>
</ol>
<p>This is simple and intuitive. The problem is that in small samples, the <span class="math inline">\(p\)</span>-values can be quite sensitive to how we split the data in the first step. This is clearly undesirable, as we will be getting different results every time we run this algorithm for no apparent reason.</p>
</section>
<section id="multi-split" class="level4">
<h4 class="anchored" data-anchor-id="multi-split">Multi Split</h4>
<p>This is a modification of the Data Split approach designed to solve the sensitivity issue and increase power.</p>
<ol type="1">
<li>Repeat <span class="math inline">\(B\)</span> times:</li>
</ol>
<ul>
<li>Reshuffle data.</li>
<li>Run the Data Split method.</li>
<li>Save the p-values.</li>
</ul>
<ol start="2" type="1">
<li>Aggregate the B <span class="math inline">\(p\)</span>-values into a single final one for each variable.</li>
</ol>
<p>Instead of splitting the data into two parts only once, we can do it many times, and each time, we get a <span class="math inline">\(p\)</span>-value for every variable. The aggregation goes a long way to solving the instability of the simple data split approach. There is a lot of clever mathematics behind it. For example, there is a complicated expression for aggregating the <span class="math inline">\(p\)</span>-values rather than taking a simple average.</p>
<p><em>Software Package</em>: <a href="https://www.rdocumentation.org/packages/hdi/">hdi</a>.</p>
</section>
<section id="bias-correction" class="level4">
<h4 class="anchored" data-anchor-id="bias-correction">Bias Correction</h4>
<p>This approach tackles the problem from a very different angle. The idea is to directly remove the bias from the naïve Lasso procedure without any subsampling or data splitting. Somewhat magically, the resulting estimator is unbiased and asymptotically normally distributed – statistical inference is then straightforward.</p>
<p>There are <a href="https://projecteuclid.org/journals/annals-of-statistics/volume-42/issue-3/On-asymptotically-optimal-confidence-regions-and-tests-for-high-dimensional/10.1214/14-AOS1221.full">multiple versions</a> of this idea, but the general form of these estimators is:</p>
<p><span class="math display">\[\hat{\beta}^{\text{bias cor}} = \hat{\beta}^{lasso} + \hat{\Theta} X'\epsilon^{lasso},\]</span></p>
<p>Where <span class="math inline">\(\hat{\beta}^{lasso}\)</span> is the lasso estimator and <span class="math inline">\(\epsilon^{lasso}\)</span> are the residuals. The missing piece is the <span class="math inline">\(\hat{\Theta}\)</span> matrix; there are several ways to estimate it depending on the setting. In its simplest form, <span class="math inline">\(\hat{\Theta}\)</span> is the inverse of the sample variance-covariance matrix. Other examples include the matrix, which minimizes an error term related to the bias as well as the variance of its Gaussian component. Similar bias-correction methods have been developed for Ridge regression as well.</p>
<p><em>Software Package</em>: <a href="https://www.rdocumentation.org/packages/hdi/">hdi</a>.</p>
</section>
<section id="bootstrap" class="level4">
<h4 class="anchored" data-anchor-id="bootstrap">Bootstrap</h4>
<p>As in many other complicated settings for statistical inference, the bootstrap can come to the rescue. Still, the plain vanilla bootstrap will not do. Instead, here is the general idea of the leading version of the bootstrap estimator for Lasso:</p>
<ol type="1">
<li>Run a Lasso regression.</li>
<li>Keep only <span class="math inline">\(\beta^{lasso}\)</span>’s larger than some magical threshold.</li>
<li>Compute the associated residuals and center them around <span class="math inline">\(0\)</span>.</li>
<li>Repeat B times:</li>
</ol>
<ul>
<li>draw random samples of these centered residuals,</li>
<li>compute new responses <span class="math inline">\(\dot{Y}\)</span> by adding them to the predictions <span class="math inline">\(X'\beta^{lasso}\)</span>, and</li>
<li>obtain <span class="math inline">\(\beta^{lasso}\)</span> coefficients from Lasso regressions on these new responses <span class="math inline">\(\dot{Y}\)</span>.</li>
</ul>
<ol start="5" type="1">
<li>Use the distribution of the obtained coefficients to conduct statistical inference.</li>
</ol>
<p>This idea can be generalized to other settings and, for instance, be combined with the bias-corrected estimator.</p>
<p>This wraps up our discussion of methods for performing hypothesis testing on equation (1) (i.e., the full model). We now move on to a more challenging topic – inference on equation (2) (i.e., the selected model).</p>
</section>
</section>
<section id="the-novel-approach-inference-on-the-selected-model" class="level3">
<h3 class="anchored" data-anchor-id="the-novel-approach-inference-on-the-selected-model">The Novel Approach: Inference on the Selected Model</h3>
<section id="posi-post-selection-inference" class="level4">
<h4 class="anchored" data-anchor-id="posi-post-selection-inference">PoSI (Post Selection Inference)</h4>
<p>The goal of the <a href="https://www.jstor.org/stable/23566582">PoSI method</a> is to construct confidence intervals that are valid regardless of the variable selection method and the selected submodel. The benefit is that we would be reaching the correct conclusion even if we did not select the true model. This luxury comes at the expense of often being too conservative (i.e., confidence intervals are “too wide”). Let me explain how this is done.</p>
<p>To take a step back, most confidence intervals in statistics take the form:</p>
<p><span class="math display">\[\hat{\beta} \pm m \times \hat{SE}(\hat{\beta}).\]</span></p>
<p>Every data scientist has seen a similar formula before. The question is usually one about choosing the constant <span class="math inline">\(m\)</span>. When we work with two-sided hypotheses tests and large samples, we often use <span class="math inline">\(m = 1.96\)</span> because this is roughly the <span class="math inline">\(97.5\)</span>th percentile of the <span class="math inline">\(t\)</span>-distribution with many degrees of freedom. This gives a <span class="math inline">\(2.5\%\)</span> false positive error on both tails of the distribution (<span class="math inline">\(5\%\)</span> in total) and hence the associated 95% confidence intervals. The larger m, the wider or more conservative the confidence interval.</p>
<p>There are a few ways to choose the constant m in the PoSI world. Vaguely speaking, PoSI says we should select this constant to equal the <span class="math inline">\(97.5\)</span>th percentile of a distribution related to the largest <span class="math inline">\(t\)</span>-statistic among all possible models. This is usually approximated with Monte Carlo simulations. Interestingly, we do not need the response variable to approximate the value.</p>
<p><span class="math display">\[m = \max_{\text{ \{all models and vars\} }} |t|.\]</span></p>
<p>Another and even more conservative choice for <span class="math inline">\(m\)</span> is the Scheffe constant.</p>
<p><span class="math display">\[m^{scheffe} = \sqrt{rank(X) \times F(rank(X),  n-p)},\]</span></p>
<p>where <span class="math inline">\(F(\dot)\)</span> denotes the <span class="math inline">\(95\)</span>th percentile of the <span class="math inline">\(F\)</span> distribution with the respective degrees of freedom.</p>
<p>Unfortunately, you guessed correctly that this method does not scale well. In some sense, it is a “brute force” method that scans through all possible model combinations and all variables within each model and picks the most conservative value. The authors recommend this procedure for datasets with roughly <span class="math inline">\(p&lt;20\)</span>. This rules out many practical applications where machine learning is most useful.</p>
<p><em>Software Package</em>: <a href="https://www.rdocumentation.org/packages/PoSI">PoSI</a></p>
</section>
<section id="eposi-exact-posi" class="level4">
<h4 class="anchored" data-anchor-id="eposi-exact-posi">EPoSI (Exact PoSI)</h4>
<p>Ok, the name of <a href="https://doi.org/10.1214/15-AOS1371">this approach</a> is not super original. The “E” here stands for “exact.” Unlike its cousin, this approach is valid only in the selected submodel. Because we cover fewer scenarios, the intervals will generally be narrower than the PoSI ones. EPoSI produces valid finite sample (as opposed to asymptotic) confidence intervals and <span class="math inline">\(p\)</span>-values. Like all methods described here, the math behind this is extremely technical. So, I will give you only a high-level description of how this works.</p>
<p>The idea is first to get the conditional distribution of <span class="math inline">\(\beta\)</span> given the selected model. A bit magically, it turns out it is a <a href="https://en.wikipedia.org/wiki/Truncated_normal_distribution">truncated normal distribution</a>. Really, who would have guessed this? Do you even remember truncated probability distributions (hint: they are just like regular PDFs but bounded from at least one side. This requires further scaling so that the density area sums to 1.)?</p>
<p>To dig one layer deeper, the authors show that the selection of Lasso predictors can be recast as a “polyhedral region” of the form:</p>
<p><span class="math display">\[ AY\leq b. \]</span></p>
<p>In English, for fixed <span class="math inline">\(X\)</span> and <span class="math inline">\(\lambda\)</span>, the set of alternative outcome values <span class="math inline">\(Y^*\)</span> which yields the same set of selected predictors, can be expressed by the simple inequality above. In it, <span class="math inline">\(A\)</span> and <span class="math inline">\(b\)</span> depend do not depend on <span class="math inline">\(Y\)</span>. Under this new result, the distribution of <span class="math inline">\(\hat{\beta}_M^{\text{EPoSI}}\)</span> is now well-understood and tractable, thus enabling valid hypothesis testing.</p>
<p>Then, we can use the conditional distribution function to construct a whimsical test statistic that is uniformly distributed on the <span class="math inline">\([0,1]\)</span> interval. And we can finally build confidence intervals based on that statistic.</p>
<p>Selective inference is currently among the hottest topic in all of statistics. There have been a myriad of extensions and improvements on the original paper. Still, this literature is painstakingly technical. What is the polyhedral selection property or a union of polytopes?</p>
<p><em>Software Package</em>: <a href="https://www.rdocumentation.org/packages/selectiveInference">selectiveInference</a>.</p>
</section>
</section>
</section>
<section id="an-example" class="level2">
<h2 class="anchored" data-anchor-id="an-example">An Example</h2>
<p>I used the popular Titanic dataset (<span class="math inline">\(n=889\)</span>) to illustrate some of the methods I discussed above. Refer to the Kaggle website carefully for the descriptions of each variable. The outcome/response variable, <code>survived</code>, indicated whether the passenger survived the disaster (mean=<span class="math inline">\(0.382\)</span>), while the predictors included demographic characteristics (e.g., <code>age</code>, <code>gender</code>) as well as some information about the travel ticket (e.g., <code>cabin number</code>, <code>fare</code>).</p>
<p>Unlike in Monte Carlo simulations, I do not know the ground truth here, so this exercise is not informative about which approaches work well and which do not. Rather, it just serves as an illustrative example.</p>
<p>Here is a table displaying the number of statistically significant variables with <span class="math inline">\(p &lt; .05\)</span> for various inference methods.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 51%">
<col style="width: 6%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 10%">
<col style="width: 5%">
<col style="width: 6%">
</colgroup>
<thead>
<tr class="header">
<th>Table 1: Number of Statistically Significant Predictors (p &lt; .05)</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td>Naive</td>
<td>Data Split</td>
<td>Multi Split</td>
<td>Bias Correct.</td>
<td>PoSI</td>
<td>EPoSI</td>
</tr>
<tr class="even">
<td># vars p &lt; .05</td>
<td>7</td>
<td>5</td>
<td>2</td>
<td>3</td>
<td>2</td>
<td>2</td>
</tr>
</tbody>
</table>
<p>As expected, the naive method results in the smallest <span class="math inline">\(p\)</span>-values and hence the highest number of significant predictors – seven. Data Split knocks down two of those seven variables, resulting in five significant ones. The rest are more conservative, leaving only two or three features with <span class="math inline">\(p &lt; .05\)</span>.</p>
<p>Below is the table with <span class="math inline">\(p\)</span>-values for all variables and each method.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 23%">
<col style="width: 11%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 17%">
<col style="width: 8%">
<col style="width: 9%">
</colgroup>
<thead>
<tr class="header">
<th>Table 2: p-values</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td>Naive</td>
<td>Data Split</td>
<td>Multi Split</td>
<td>Bias Correct.</td>
<td>PoSI</td>
<td>EPoSI</td>
</tr>
<tr class="even">
<td></td>
<td>0.00</td>
<td>0.00</td>
<td>0.00</td>
<td>0.00</td>
<td>0.01</td>
<td>1.00</td>
</tr>
<tr class="odd">
<td><code>age</code></td>
<td>0.00</td>
<td>0.04</td>
<td>1.00</td>
<td>0.01</td>
<td>1.00</td>
<td>1.00</td>
</tr>
<tr class="even">
<td><code>sibsp</code></td>
<td>0.02</td>
<td>0.03</td>
<td>1.00</td>
<td>0.21</td>
<td>1.00</td>
<td>1.00</td>
</tr>
<tr class="odd">
<td><code>parch</code></td>
<td>0.32</td>
<td>0.64</td>
<td>1.00</td>
<td>1.00</td>
<td>1.00</td>
<td>1.00</td>
</tr>
<tr class="even">
<td><code>fare</code></td>
<td>0.20</td>
<td>0.21</td>
<td>1.00</td>
<td>1.00</td>
<td>1.00</td>
<td>1.00</td>
</tr>
<tr class="odd">
<td><code>male</code></td>
<td>0.00</td>
<td>0.00</td>
<td>0.00</td>
<td>0.00</td>
<td>0.01</td>
<td>0.00</td>
</tr>
<tr class="even">
<td><code>embarkedS</code></td>
<td>0.00</td>
<td>0.01</td>
<td>1.00</td>
<td>0.06</td>
<td>-</td>
<td>1.00</td>
</tr>
<tr class="odd">
<td><code>cabinA</code></td>
<td>0.39</td>
<td>-</td>
<td>1.00</td>
<td>1.00</td>
<td>1.00</td>
<td>1.00</td>
</tr>
<tr class="even">
<td><code>cabinB</code></td>
<td>0.35</td>
<td>-</td>
<td>1.00</td>
<td>1.00</td>
<td>1.00</td>
<td>1.00</td>
</tr>
<tr class="odd">
<td><code>cabinD</code></td>
<td>0.05</td>
<td>0.27</td>
<td>1.00</td>
<td>0.44</td>
<td>1.00</td>
<td>-</td>
</tr>
<tr class="even">
<td><code>cabinE</code></td>
<td>0.00</td>
<td>0.64</td>
<td>1.00</td>
<td>0.06</td>
<td>1.00</td>
<td>1.00</td>
</tr>
<tr class="odd">
<td><code>cabinF</code></td>
<td>0.02</td>
<td>0.52</td>
<td>1.00</td>
<td>0.21</td>
<td>1.00</td>
<td>1.00</td>
</tr>
<tr class="even">
<td><code>embarkedC</code></td>
<td>-</td>
<td>-</td>
<td>1.00</td>
<td>0.11</td>
<td>1.00</td>
<td>1.00</td>
</tr>
<tr class="odd">
<td><code>embarkedQ</code></td>
<td>-</td>
<td>-</td>
<td>1.00</td>
<td>1.00</td>
<td>1.00</td>
<td>0.00</td>
</tr>
<tr class="even">
<td><code>cabinC</code></td>
<td>-</td>
<td>-</td>
<td>1.00</td>
<td>1.00</td>
<td>1.00</td>
<td>-</td>
</tr>
</tbody>
</table>
<p>You can find the code for this exercise in this GitHub repo.</p>
</section>
<section id="bottom-line" class="level2">
<h2 class="anchored" data-anchor-id="bottom-line">Bottom Line</h2>
<ul>
<li><p>Machine learning methods mine through datasets to find strong correlations between the response and the features. Quantifying this strength is an open and challenging problem.</p></li>
<li><p>The naive approach to hypothesis testing is usually invalid.</p></li>
<li><p>There are two main approaches that work – inference on the full model or on the selected model. The latter poses more technical challenges than the former.</p></li>
<li><p>If we are interested in the full model, the Multi Split approach is general enough to cover a wide range of models and settings.</p></li>
<li><p>If we believe you have to focus on the selected model, EPoSI is the state-of-the-art.</p></li>
<li><p><a href="https://doi.org/10.1214/14-STS507">Simulation</a> <a href="https://www.jstor.org/stable/24780819">exercises</a> usually show no clear winner, as none of the methods consistently outperforms the rest.</p></li>
</ul>
</section>
<section id="where-to-learn-more" class="level2">
<h2 class="anchored" data-anchor-id="where-to-learn-more">Where to Learn More</h2>
<p><a href="https://doi.org/10.1073/pnas.1507583112">Taylor and Tibshirani (2015)</a> give a non-technical introduction to the problem space along with a description of the POSI method – a great read but focused on a single approach. <a href="https://doi.org/10.1214/14-STS507">Other</a> <a href="https://www.jstor.org/stable/24780819add">studies</a> both provide a relatively accessible overview of the various methods for statistical inference on the full model. For technical readers, <a href="https://doi.org/10.1214/22-SS135">Zhang et al.&nbsp;(2022)</a> provide an excellent up-to-date review of the literature, which I used extensively.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<p>Berk, R., Brown, L., Buja, A., Zhang, K., &amp; Zhao, L. (2013). Valid post-selection inference. The Annals of Statistics, 802-837.</p>
<p>Bühlmann, P. (2013). Statistical significance in high-dimensional linear models. Bernoulli, 19(4), 1212-1242.</p>
<p>Dezeure, R., Bühlmann, P., Meier, L., &amp; Meinshausen, N. (2015). High-dimensional inference: confidence intervals, p-values and R-software hdi. Statistical Science, 533-558.</p>
<p>Javanmard, A., &amp; Montanari, A. (2014). Confidence intervals and hypothesis testing for high-dimensional regression. The Journal of Machine Learning Research, 15(1), 2869-2909.</p>
<p>Lee, J. D., Sun, D. L., Sun, Y., &amp; Taylor, J. E. (2016). Exact post-selection inference, with application to the lasso. The Annals of Statistics, 44(3), 907-927.</p>
<p>Leeb, H., &amp; Pötscher, B. M. (2005). Model selection and inference: Facts and fiction. Econometric Theory, 21(1), 21-59.</p>
<p>Leeb, H., Pötscher, B. M., &amp; Ewald, K. (2015). On various confidence intervals post-model-selection. Statistical Science, 30(2), 216-227.</p>
<p>Meinshausen, N., Meier, L., &amp; Bühlmann, P. (2009). P-values for high-dimensional regression. Journal of the American Statistical Association, 104(488), 1671-1681.</p>
<p>Taylor, J., &amp; Tibshirani, R. J. (2015). Statistical learning and selective inference. Proceedings of the National Academy of Sciences, 112(25), 7629-7634.</p>
<p>Van de Geer, S., Bühlmann, P., Ritov, Y. A., &amp; Dezeure, R. (2014). On asymptotically optimal confidence regions and tests for high-dimensional models. The Annals of Statistics, 42(3), 1166-1202.</p>
<p>Wasserman, L., &amp; Roeder, K. (2009). High dimensional variable selection. Annals of Statistics, 37(5A), 2178.</p>
<p>Zhang, D., Khalili, A., &amp; Asgharian, M. (2022). Post-model-selection inference in linear regression models: An integrated review. Statistics Surveys, 16, 86-136.</p>
<p>Zhang, C. H., &amp; Zhang, S. S. (2014). Confidence intervals for low dimensional parameters in high dimensional linear models. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 76(1), 217-242.</p>
<p>Zhao, S., Witten, D., &amp; Shojaie, A. (2021). In defense of the indefensible: A very naive approach to high-dimensional inference. Statistical Science, 36(4), 562-577.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    window.setColorSchemeToggle(window.hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/yourusername\.github\.io\/your-site");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© 2025 Vasco Yasenov</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>Powered by <a href="https://quarto.org">Quarto</a></p>
</div>
  </div>
</footer>




</body></html>